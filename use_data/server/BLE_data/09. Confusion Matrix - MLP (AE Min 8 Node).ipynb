{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix - MLP (AE Min 8 Node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"..\\\\..\\\\..\\\\data\\\\BLE_data\\\\\"\n",
    "def read_test_data(set_num, model_name, mode):\n",
    "    if model_name == 5:\n",
    "        raw_data = np.loadtxt(base_dir + \"raw_data\\\\in_\" + mode + \"_\" + str(set_num) + '.csv', delimiter=',', dtype=np.float32)\n",
    "    elif model_name == 6:\n",
    "        raw_data = np.loadtxt(base_dir + \"raw_data\\\\out_\" + mode + \"_\" + str(set_num) + '.csv', delimiter=',', dtype=np.float32)\n",
    "    b_data    = raw_data[:,0:3]\n",
    "    cell_data = raw_data[:,3:13]\n",
    "\n",
    "    return b_data, cell_data\n",
    "\n",
    "def read_denoised_test_data(set_num, model_name, mode):\n",
    "    if model_name == 5:\n",
    "        raw_data = np.loadtxt(base_dir + \"filtered_data\\\\in_\" + mode + \"_\" + str(set_num) + '_denoised.csv', delimiter=',', dtype=np.float32)\n",
    "    elif model_name == 6:\n",
    "        raw_data = np.loadtxt(base_dir + \"filtered_data\\\\out_\" + mode + \"_\" + str(set_num) + '_denoised.csv', delimiter=',', dtype=np.float32)\n",
    "    b_data    = raw_data[:,0:3]\n",
    "    cell_data = raw_data[:,3:13]\n",
    "\n",
    "    return b_data, cell_data\n",
    "\n",
    "def one_hot_convert_normal(data, end_line, output_num):\n",
    "    list_data = []\n",
    "\n",
    "    for row in range(0, end_line):\n",
    "        for column in range(0, output_num):\n",
    "            if data[row][column] == 1:\n",
    "                list_data.append(column + 1)\n",
    "    return list_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name: 5 (car_in) / 6 (car_out)\n",
    "# Car-in data\n",
    "model_name = 5\n",
    "set_num = 6000\n",
    "train_set_num = int(set_num * 0.75)\n",
    "test_set_num = int(set_num * 0.25)\n",
    "\n",
    "x_in_train_noisy, y_in_train_noisy = read_test_data(train_set_num, model_name, \"train\")\n",
    "x_in_train_denoised, y_in_train_denoised = read_denoised_test_data(train_set_num, model_name, \"train\")\n",
    "x_in_test_noisy, y_in_test_noisy = read_test_data(test_set_num, model_name, \"test\")\n",
    "x_in_test_denoised, y_in_test_denoised = read_denoised_test_data(test_set_num, model_name, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name: 5 (car_in) / 6 (car_out)\n",
    "# Car-out data\n",
    "model_name = 6\n",
    "set_num = 6000\n",
    "train_set_num = int(set_num * 0.75)\n",
    "test_set_num = int(set_num * 0.25)\n",
    "\n",
    "x_out_train_noisy, y_out_train_noisy = read_test_data(train_set_num, model_name, \"train\")\n",
    "x_out_train_denoised, y_out_train_denoised = read_denoised_test_data(train_set_num, model_name, \"train\")\n",
    "x_out_test_noisy, y_out_test_noisy = read_test_data(test_set_num, model_name, \"test\")\n",
    "x_out_test_denoised, y_out_test_denoised = read_denoised_test_data(test_set_num, model_name, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Car-in\n",
    "ae_x_in_train_noisy = x_in_train_noisy.astype('float32') / -100.\n",
    "ae_x_in_train_denoised = x_in_train_denoised.astype('float32') / -100.\n",
    "ae_x_in_test_noisy = x_in_test_noisy.astype('float32') / -100.\n",
    "ae_x_in_test_denoised = x_in_test_denoised.astype('float32') / -100.\n",
    "# Car-out\n",
    "ae_x_out_train_noisy = x_out_train_noisy.astype('float32') / -100.\n",
    "ae_x_out_train_denoised = x_out_train_denoised.astype('float32') / -100.\n",
    "ae_x_out_test_noisy = x_out_test_noisy.astype('float32') / -100.\n",
    "ae_x_out_test_denoised = x_out_test_denoised.astype('float32') / -100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "output_num = 10\n",
    "end_line = train_set_num * output_num\n",
    "\n",
    "oh_y_in_train_denoised = one_hot_convert_normal(y_in_train_denoised, end_line, output_num)\n",
    "oh_y_in_train_denoised = np.array(oh_y_in_train_denoised)\n",
    "\n",
    "oh_y_out_train_denoised = one_hot_convert_normal(y_out_train_denoised, end_line, output_num)\n",
    "oh_y_out_train_denoised = np.array(oh_y_out_train_denoised)\n",
    "\n",
    "# Testing data\n",
    "end_line = test_set_num * output_num\n",
    "\n",
    "oh_y_in_test_denoised = one_hot_convert_normal(y_in_test_denoised, end_line, output_num)\n",
    "oh_y_in_test_denoised = np.array(oh_y_in_test_denoised)\n",
    "\n",
    "oh_y_out_test_denoised = one_hot_convert_normal(y_out_test_denoised, end_line, output_num)\n",
    "oh_y_out_test_denoised = np.array(oh_y_out_test_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_01 = load_model('autoencoder_01.h5')\n",
    "autoencoder_02 = load_model('autoencoder_02.h5')\n",
    "autoencoder_03 = load_model('autoencoder_03.h5')\n",
    "autoencoder_04 = load_model('autoencoder_04.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ 방법 1 ]\n",
    "## 데이터 10개의 평균 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def average(x, y, set_num, data_num):\n",
    "    idx = 0\n",
    "    sum = np.array([0, 0, 0])\n",
    "    data = [[0 for col in range(3)] for row in range(int(set_num * 10 / data_num))]\n",
    "    label = [[0 for col in range(10)] for row in range(int(set_num * 10 / data_num))]\n",
    "    for i in range(set_num * 10):\n",
    "        for j in range(3):\n",
    "            sum[j] += x[i][j]\n",
    "        if(i % data_num == data_num - 1):\n",
    "            for j in range(3):\n",
    "                data[idx][j] = int(round(sum[j] / data_num))\n",
    "            for j in range(10):\n",
    "                label[idx][j] = y[i][j]\n",
    "            idx += 1\n",
    "            sum = np.array([0, 0, 0])    \n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_autoencoder_x_train = autoencoder_01.predict(ae_x_in_train_noisy) * (-100)\n",
    "x_train, y_train = average(after_autoencoder_x_train, y_in_train_noisy, 4500, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_autoencoder_x_test = autoencoder_01.predict(ae_x_in_test_noisy) * (-100)\n",
    "x_test, y_test = average(after_autoencoder_x_test, y_in_test_noisy, 1500, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "ae_x_in_train = x_train.astype('float32') / -100.\n",
    "ae_x_in_test = x_test.astype('float32') / -100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average data\n",
    "# Train data\n",
    "oh_y_in_train = one_hot_convert_normal(y_train, int(4500 * output_num / 10), output_num)\n",
    "oh_y_in_train = np.array(oh_y_in_train)\n",
    "\n",
    "# Test data\n",
    "oh_y_in_test = one_hot_convert_normal(y_test, int(1500 * output_num / 10), output_num)\n",
    "oh_y_in_test = np.array(oh_y_in_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 01\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   0 4472    0    0    0    0    0    0    0   28]\n",
      " [   0 4357    0    0    8    0    0   18    0  117]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0   76  603    0  157 1560   71 1519    0  514]\n",
      " [4486    0    0    0    0    0    0    5    0    9]\n",
      " [   0 4496    0    0    0    0    0    0    0    4]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0 1492    0    0    0    0    0    0    0    8]\n",
      " [   0 1450    0    0    6    0    0    5    0   39]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0   28  199    0   52  477   24  529    0  191]\n",
      " [1492    0    0    0    0    0    0    2    0    6]\n",
      " [   0 1499    0    0    0    0    0    0    0    1]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 02\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]\n",
      " [ 256    0  293  637  211 1224  467 1412    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]\n",
      " [  72    0   84  234   74  420  159  457    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 03\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]\n",
      " [  49    0  602   18    2 3661  100   68    0    0]\n",
      " [4489    0    3    1    1    1    5    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]\n",
      " [  15    0  209    4    1 1223   28   20    0    0]\n",
      " [1496    0    2    1    0    0    0    1    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 04\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[3414    0  109   64   84  158  366  285    0   20]\n",
      " [1269    0   42   23  349  788  130 1279    0  620]\n",
      " [ 280    0  789  102   28 1763  741  780    0   17]\n",
      " [1109    0  584   66   55 1061  672  948    0    5]\n",
      " [1694    0  173   34 1386  337  310  558    0    8]\n",
      " [ 258    0  506   12    0 2236  446 1042    0    0]\n",
      " [ 396    0  869   61    9 1515  937  711    0    2]\n",
      " [  13    0  177    8   40 1525   78 2658    0    1]\n",
      " [1654    0  310   64   56  847  496 1072    0    1]\n",
      " [ 651    0  289   69  498  497  461 1181    0  854]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1146    0   38   23   20   49  122   94    0    8]\n",
      " [ 434    0    7   10  108  275   39  382    0  245]\n",
      " [  79    0  285   36    8  597  248  245    0    2]\n",
      " [ 380    0  206   25   17  340  219  310    0    3]\n",
      " [ 587    0   61   14  409  145  104  179    0    1]\n",
      " [  97    0  155    3    1  729  148  367    0    0]\n",
      " [ 124    0  284   38    4  498  320  231    0    1]\n",
      " [   3    0   66    3   18  517   25  868    0    0]\n",
      " [ 509    0   97   27   18  321  192  336    0    0]\n",
      " [ 232    0   86   35  152  172  159  373    0  291]]\n",
      "\n",
      "---\n",
      "\n",
      "test 05\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   1 4101    1    0   32   23    2   52    0  288]\n",
      " [  87 3648    1    0   65   19    0   72    0  608]\n",
      " [  91 4146   55    2    7   87   14   33    0   65]\n",
      " [   4 4200   13    0   31   72    0   85    0   95]\n",
      " [   1 4461    7    0    2   14    0    5    0   10]\n",
      " [   0 4496    0    0    1    2    0    1    0    0]\n",
      " [ 130  845  100    0  124 1672   32 1235    0  362]\n",
      " [2670  692   59    0   15  795   32  188    0   49]\n",
      " [  57 4084   33    0   18  107   10  108    0   83]\n",
      " [  13 4113   14    0   33   52    4  120    0  151]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0 1358    1    0   11    3    0   16    0  111]\n",
      " [  32 1191    2    0   24    9    1   34    0  207]\n",
      " [  21 1392   18    0    2   31    5   11    0   20]\n",
      " [   0 1388    7    0    9   24    0   31    0   41]\n",
      " [   1 1489    0    0    0    4    0    2    0    4]\n",
      " [   0 1498    1    0    0    1    0    0    0    0]\n",
      " [  50  278   35    0   50  543    8  406    0  130]\n",
      " [ 874  223   17    0    4  284   11   65    0   22]\n",
      " [  26 1370    6    0    2   36    5   30    0   25]\n",
      " [   3 1356    9    0   14   10    1   59    0   48]]\n",
      "\n",
      "---\n",
      "\n",
      "test 06\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[  0 446   0   0   0   0   0   0   0   4]\n",
      " [  0 422   0   0   0   0   0  22   0   6]\n",
      " [  0 449   0   0   0   0   0   0   0   1]\n",
      " [  0 445   0   0   0   0   0   0   0   5]\n",
      " [  0 450   0   0   0   0   0   0   0   0]\n",
      " [  0 450   0   0   0   0   0   0   0   0]\n",
      " [  0   0 109   0   1 255   0  85   0   0]\n",
      " [450   0   0   0   0   0   0   0   0   0]\n",
      " [  0 449   0   0   0   1   0   0   0   0]\n",
      " [  0 444   0   0   0   0   0   1   0   5]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[  0 149   0   0   0   0   0   0   0   1]\n",
      " [  0 145   0   0   0   0   0   4   0   1]\n",
      " [  0 150   0   0   0   0   0   0   0   0]\n",
      " [  0 150   0   0   0   0   0   0   0   0]\n",
      " [  0 150   0   0   0   0   0   0   0   0]\n",
      " [  0 150   0   0   0   0   0   0   0   0]\n",
      " [  0   0  42   0   0  75   0  33   0   0]\n",
      " [149   0   0   0   0   1   0   0   0   0]\n",
      " [  0 150   0   0   0   0   0   0   0   0]\n",
      " [  0 149   0   0   0   0   0   0   0   1]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_01 = pickle.load(open('mlp_01.sav', 'rb'))\n",
    "\n",
    "print(\"test 01\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train_denoised) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test_denoised) * (-100)\n",
    "\n",
    "prediction = mlp_01.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_01.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 02\\n\")\n",
    "prediction = mlp_01.predict(x_out_train_denoised)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_01.predict(x_out_test_denoised)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 03\\n\")\n",
    "after_autoencoder_x_train = autoencoder_02.predict(ae_x_out_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_02.predict(ae_x_out_test_noisy) * (-100)\n",
    "\n",
    "prediction = mlp_01.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_01.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 04\\n\")\n",
    "after_autoencoder_x_train = autoencoder_03.predict(ae_x_in_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_03.predict(ae_x_in_test_noisy) * (-100)\n",
    "\n",
    "prediction = mlp_01.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_01.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 05\\n\")\n",
    "after_autoencoder_x_train = autoencoder_01.predict(ae_x_in_train_noisy)\n",
    "after_autoencoder_x_test = autoencoder_01.predict(ae_x_in_test_noisy)\n",
    "after_autoencoder_x_train = autoencoder_04.predict(after_autoencoder_x_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(after_autoencoder_x_test) * (-100)\n",
    "\n",
    "prediction = mlp_01.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_01.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"test 06\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test) * (-100)\n",
    "\n",
    "prediction = mlp_01.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_in_train, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_01.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_in_test, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 01\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4392   70    0    0    0    0   28    0    0   10]\n",
      " [ 124 3930    5    0    0    0  149    0    0  292]\n",
      " [   0    0 4492    0    0    0    0    0    8    0]\n",
      " [ 169    5    0 4186  122    0    0    0   18    0]\n",
      " [   0    0    0   46 4149   19    0    0  286    0]\n",
      " [   0    0    0    0    0 4312    0    0  188    0]\n",
      " [   1   50    0    0    0    0 4441    0    7    1]\n",
      " [   0    0    0    0    0    0   32 4468    0    0]\n",
      " [   0    0    4   69  236  191    5    0 3995    0]\n",
      " [   0  176    0    0    0    0    0    0    0 4324]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1469   20    0    0    0    0    8    0    0    3]\n",
      " [  44 1287    4    0    0    0   52    0    0  113]\n",
      " [   0    0 1498    0    0    0    0    0    2    0]\n",
      " [  61    0    1 1388   43    0    0    0    7    0]\n",
      " [   0    0    0   12 1384    3    0    0  101    0]\n",
      " [   0    0    0    0    0 1447    0    0   53    0]\n",
      " [   0   17    0    0    0    0 1479    0    3    1]\n",
      " [   0    0    0    0    0    0   16 1484    0    0]\n",
      " [   0    0    1   26   83   76    1    0 1313    0]\n",
      " [   0   46    0    0    0    0    0    0    0 1454]]\n",
      "\n",
      "---\n",
      "\n",
      "test 02\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[3992    0    0    0    0    0    0    0    0  508]\n",
      " [  20 4443   19   18    0    0    0    0    0    0]\n",
      " [   0  628 3872    0    0    0    0    0    0    0]\n",
      " [   0    0    0 2951 1543    0    0    0    6    0]\n",
      " [   0    0    0 1470 2948    0    0    0   82    0]\n",
      " [   0    0    0    0    0 4500    0    0    0    0]\n",
      " [   0    0    0    0    0    0 4098  402    0    0]\n",
      " [   0    0    0    0    0    0  314 4186    0    0]\n",
      " [   0  236   23  237    0    0    1    0 4003    0]\n",
      " [   0    1    0    0    0    0    0    0    0 4499]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1339    0    0    0    0    0    0    0    0  161]\n",
      " [   6 1485    6    3    0    0    0    0    0    0]\n",
      " [   0  194 1306    0    0    0    0    0    0    0]\n",
      " [   0    0    0  984  512    0    0    0    4    0]\n",
      " [   0    0    0  498  979    0    0    0   23    0]\n",
      " [   0    0    0    0    0 1500    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1387  113    0    0]\n",
      " [   0    0    0    0    0    0   97 1403    0    0]\n",
      " [   0   83   12   70    0    0    0    0 1335    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]]\n",
      "\n",
      "---\n",
      "\n",
      "test 03\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4322   54    1    0    0    0    0    0    0  123]\n",
      " [  26 4304    8    0    0    0    0    0    0  162]\n",
      " [   0   32 4460    5    0    0    0    0    3    0]\n",
      " [   0    0    0 4431   64    4    0    0    1    0]\n",
      " [   0    0   12  114 4345   23    0    0    6    0]\n",
      " [   0    0    0    0   17 4475    0    0    8    0]\n",
      " [   0    0    0    0    0    0 4476   24    0    0]\n",
      " [   0    0    0    0    0    0   15 4485    0    0]\n",
      " [   0    1    6    4    1    0    0    0 4488    0]\n",
      " [ 125   18    0    0    0    0    0    0    0 4357]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1444   16    0    0    0    0    0    0    0   40]\n",
      " [   5 1425    5    0    0    0    0    0    0   65]\n",
      " [   0    9 1483    5    2    0    0    0    1    0]\n",
      " [   0    0    0 1470   26    3    0    0    1    0]\n",
      " [   0    0    5   31 1452    8    0    0    4    0]\n",
      " [   0    0    0    0    8 1490    0    0    2    0]\n",
      " [   0    0    0    0    0    0 1492    8    0    0]\n",
      " [   0    0    0    0    0    0    5 1495    0    0]\n",
      " [   0    0    0    3    0    0    0    0 1497    0]\n",
      " [  40    4    0    0    0    0    0    0    0 1456]]\n",
      "\n",
      "---\n",
      "\n",
      "test 04\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   0    0    0    0    0    0  607 3893    0    0]\n",
      " [   0    0    0    0    0    0 3071 1429    0    0]\n",
      " [   0    0    0    0    0    0 2603 1897    0    0]\n",
      " [   0    0    0    0    0    0 2425 2075    0    0]\n",
      " [   0    0    0    0    0    0 2216 2284    0    0]\n",
      " [   0    0    0    0    0    0 2531 1969    0    0]\n",
      " [   0    0    0    0    0    0 2683 1817    0    0]\n",
      " [   0    0    0    0    0    0 4276  224    0    0]\n",
      " [   0    0    0    0    0    0 1854 2646    0    0]\n",
      " [   0    0    0    0    0    0 3024 1476    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0    0    0    0    0    0  194 1306    0    0]\n",
      " [   0    0    0    0    0    0 1019  481    0    0]\n",
      " [   0    0    0    0    0    0  861  639    0    0]\n",
      " [   0    0    0    0    0    0  810  690    0    0]\n",
      " [   0    0    0    0    0    0  703  797    0    0]\n",
      " [   0    0    0    0    0    0  861  639    0    0]\n",
      " [   0    0    0    0    0    0  890  610    0    0]\n",
      " [   0    0    0    0    0    0 1412   88    0    0]\n",
      " [   0    0    0    0    0    0  631  869    0    0]\n",
      " [   0    0    0    0    0    0  980  520    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 05\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[3290  405   24  213   30    0  424    0   12  102]\n",
      " [ 171 3061    2    8    0    0  819   84    1  354]\n",
      " [  14  167 3500    8    0    0  275   81   51  404]\n",
      " [ 451   52   50 3177  324    0  301    2  133   10]\n",
      " [ 298    2   12  364 3207   43   39    1  533    1]\n",
      " [   0    0    1  103   97 1163    4    0 3132    0]\n",
      " [ 165  330   89   54    0    0 3555  127    3  177]\n",
      " [   0  222  287    8    3    0 1178 2637   25  140]\n",
      " [ 204   79  130  609  537   34  373   52 2429   53]\n",
      " [ 278  571  393    6    0    0  395   11    1 2845]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1074  127    7   85   10    0  154    0    6   37]\n",
      " [  56 1002    2    4    0    0  289   31    0  116]\n",
      " [   3   53 1173    2    0    0   95   16   12  146]\n",
      " [ 165   16   14 1046   94    0  114    0   40   11]\n",
      " [  99    1    5  133 1050   10   10    1  191    0]\n",
      " [   0    0    1   31   35  417    2    0 1014    0]\n",
      " [  54  110   25   14    0    0 1184   48    1   64]\n",
      " [   1   73  104    2    0    0  417  863    8   32]\n",
      " [  65   20   46  202  189   12  108   25  815   18]\n",
      " [  73  205  111    2    0    0  148    2    1  958]]\n",
      "\n",
      "---\n",
      "\n",
      "test 06\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[436  10   0   0   0   0   4   0   0   0]\n",
      " [  0 422   0   0   0   0  28   0   0   0]\n",
      " [  0   2 447   0   0   0   1   0   0   0]\n",
      " [  0   0   0 445   0   0   5   0   0   0]\n",
      " [  0   0   0  11 421   0   0   0  18   0]\n",
      " [  0   0   0   0   0 341   0   0 109   0]\n",
      " [  0   0   0   0   0   0 450   0   0   0]\n",
      " [  0   0   0   0   0   0   3 447   0   0]\n",
      " [  0   0   0  18   0   0   2   0 430   0]\n",
      " [  0  18   0   0   0   0   6   0   0 426]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[142   5   0   0   0   0   1   0   0   2]\n",
      " [  0 145   0   0   0   0   5   0   0   0]\n",
      " [  0   0 150   0   0   0   0   0   0   0]\n",
      " [  0   0   0 150   0   0   0   0   0   0]\n",
      " [  0   0   0   1 144   0   0   0   5   0]\n",
      " [  0   0   0   0   0 110   0   0  40   0]\n",
      " [  0   0   0   0   0   0 150   0   0   0]\n",
      " [  0   0   0   0   0   0   3 147   0   0]\n",
      " [  0   0   0   6   0   0   0   0 144   0]\n",
      " [  0   7   0   0   0   0   1   0   0 142]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_02 = pickle.load(open('mlp_02.sav', 'rb'))\n",
    "\n",
    "print(\"test 01\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train_denoised) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test_denoised) * (-100)\n",
    "\n",
    "prediction = mlp_02.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_02.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 02\\n\")\n",
    "prediction = mlp_02.predict(x_out_train_denoised)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_02.predict(x_out_test_denoised)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 03\\n\")\n",
    "after_autoencoder_x_train = autoencoder_02.predict(ae_x_out_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_02.predict(ae_x_out_test_noisy) * (-100)\n",
    "\n",
    "prediction = mlp_02.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_02.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 04\\n\")\n",
    "after_autoencoder_x_train = autoencoder_03.predict(ae_x_in_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_03.predict(ae_x_in_test_noisy) * (-100)\n",
    "\n",
    "prediction = mlp_02.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_02.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 05\\n\")\n",
    "after_autoencoder_x_train = autoencoder_01.predict(ae_x_in_train_noisy)\n",
    "after_autoencoder_x_test = autoencoder_01.predict(ae_x_in_test_noisy)\n",
    "after_autoencoder_x_train = autoencoder_04.predict(after_autoencoder_x_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(after_autoencoder_x_test) * (-100)\n",
    "\n",
    "prediction = mlp_02.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_02.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"test 06\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test) * (-100)\n",
    "\n",
    "prediction = mlp_02.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_in_train, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_02.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_in_test, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 01\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4230  203    0    0    0    0   39    0    0   28]\n",
      " [ 123 3917    6    0    0    0  160    0    0  294]\n",
      " [   0    0 4492    0    0    0    0    0    8    0]\n",
      " [  99   74    1 4118  192    0    0    0   16    0]\n",
      " [   0    0    0   39 4215   32    0    0  214    0]\n",
      " [   0    0    0    0    8 4338    0    0  154    0]\n",
      " [   0   45    0    0    0    0 4436    0   13    6]\n",
      " [   0    0    0    0    0    0   28 4472    0    0]\n",
      " [   0    0    4   44  310  249    4    0 3889    0]\n",
      " [   0  169    0    0    0    0    0    0    0 4331]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1415   68    0    0    0    0   10    0    0    7]\n",
      " [  46 1279    4    0    0    0   58    0    0  113]\n",
      " [   0    0 1498    0    0    0    0    0    2    0]\n",
      " [  38   23    1 1367   65    0    0    0    6    0]\n",
      " [   0    0    0   12 1412    8    0    0   68    0]\n",
      " [   0    0    0    0    2 1455    0    0   43    0]\n",
      " [   0   17    0    0    0    0 1477    0    5    1]\n",
      " [   0    0    0    0    0    0   11 1489    0    0]\n",
      " [   0    0    1   17  104   90    1    0 1287    0]\n",
      " [   0   45    0    0    0    0    0    0    0 1455]]\n",
      "\n",
      "---\n",
      "\n",
      "test 02\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4328    0    0    0    0    0    0    0    0  172]\n",
      " [   0 4394  104    0    0    0    0    0    0    2]\n",
      " [   0  621 3619    0    0    0    0    0  260    0]\n",
      " [   0    0    0 2130 2367    0    0    0    3    0]\n",
      " [   0    0    0 1243 3135  120    0    0    2    0]\n",
      " [   0    0    0    0    0 4500    0    0    0    0]\n",
      " [   0    0    0    0    0    0 4232  268    0    0]\n",
      " [   0    0    0    0    0    0   68 4432    0    0]\n",
      " [   0    2   14  202   33    0    8    0 4241    0]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1438    0    0    0    0    0    0    0    0   62]\n",
      " [   0 1463   37    0    0    0    0    0    0    0]\n",
      " [   0  192 1219    0    0    0    0    0   89    0]\n",
      " [   0    0    0  689  807    0    0    0    4    0]\n",
      " [   0    0    0  434 1016   49    0    0    1    0]\n",
      " [   0    0    0    0    0 1500    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1423   77    0    0]\n",
      " [   0    0    0    0    0    0   27 1473    0    0]\n",
      " [   0    0    4   62    6    0    5    0 1423    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]]\n",
      "\n",
      "---\n",
      "\n",
      "test 03\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4363   50    1    0    0    0    0    0    0   86]\n",
      " [  35 4288   14    0    0    0    0    0    0  163]\n",
      " [   0   20 4468    1    3    0    0    0    8    0]\n",
      " [   0    0    0 4415   80    4    0    0    1    0]\n",
      " [   0    0   11   83 4362   36    0    0    8    0]\n",
      " [   0    0    0    0   17 4481    0    0    2    0]\n",
      " [   0    0    0    0    0    0 4471   29    0    0]\n",
      " [   0    0    0    0    0    0   14 4486    0    0]\n",
      " [   0    0    5    3    4    0    0    0 4488    0]\n",
      " [ 158   18    0    0    0    0    0    0    0 4324]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1460   16    0    0    0    0    0    0    0   24]\n",
      " [  10 1420    5    0    0    0    0    0    0   65]\n",
      " [   0    5 1487    1    2    1    0    0    4    0]\n",
      " [   0    0    0 1467   29    3    0    0    1    0]\n",
      " [   0    0    5   22 1460   11    0    0    2    0]\n",
      " [   0    0    0    0    9 1491    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1491    9    0    0]\n",
      " [   0    0    0    0    0    0    5 1495    0    0]\n",
      " [   0    0    0    2    2    0    0    0 1496    0]\n",
      " [  47    4    0    0    0    0    0    0    0 1449]]\n",
      "\n",
      "---\n",
      "\n",
      "test 04\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   0    0    0    0    0    0  680 3820    0    0]\n",
      " [   0    0    0    0    0    0 3089 1411    0    0]\n",
      " [   0    0    0    0    0    0 3211 1289    0    0]\n",
      " [   0    0    0    0    0    0 2663 1837    0    0]\n",
      " [   0    0    0    0    0    0 2395 2105    0    0]\n",
      " [   0    0    0    0    0    0 3528  972    0    0]\n",
      " [   0    0    0    0    0    0 3158 1342    0    0]\n",
      " [   0    0    0    0    0    0 4381  119    0    0]\n",
      " [   0    0    0    0    0    0 2157 2343    0    0]\n",
      " [   0    0    0    0    0    0 3229 1271    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0    0    0    0    0    0  213 1287    0    0]\n",
      " [   0    0    0    0    0    0 1025  475    0    0]\n",
      " [   0    0    0    0    0    0 1073  427    0    0]\n",
      " [   0    0    0    0    0    0  878  622    0    0]\n",
      " [   0    0    0    0    0    0  780  720    0    0]\n",
      " [   0    0    0    0    0    0 1179  321    0    0]\n",
      " [   0    0    0    0    0    0 1039  461    0    0]\n",
      " [   0    0    0    0    0    0 1460   40    0    0]\n",
      " [   0    0    0    0    0    0  733  767    0    0]\n",
      " [   0    0    0    0    0    0 1044  456    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 05\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[3217  440   42  172   64    0  466    0    6   93]\n",
      " [ 153 2991    2    8    0    0  872   85    1  388]\n",
      " [  14  153 3497    5    4    0  272   84   63  408]\n",
      " [ 393   91   69 3093  416    0  309    2  117   10]\n",
      " [ 271   25   16  320 3337   49   39    1  441    1]\n",
      " [   0    0    1   92  138 1480    4    0 2785    0]\n",
      " [ 133  311   97   47    0    0 3570  127    9  206]\n",
      " [   0  210  285    8    4    0 1174 2646   30  143]\n",
      " [ 181   76  137  492  734   62  387   53 2319   59]\n",
      " [ 279  517  406    3    3    0  410   11    1 2870]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1052  136    9   75   22    0  166    0    4   36]\n",
      " [  54  986    2    4    0    0  297   31    0  126]\n",
      " [   3   48 1169    2    0    0   95   16   20  147]\n",
      " [ 144   30   21 1022  117    0  115    0   37   14]\n",
      " [  86   10    5  117 1104   11   11    1  155    0]\n",
      " [   0    0    1   29   44  514    2    0  910    0]\n",
      " [  44  108   27   13    0    0 1193   48    1   66]\n",
      " [   0   63  105    2    1    0  416  865   14   34]\n",
      " [  60   17   50  164  259   16  111   25  778   20]\n",
      " [  71  190  114    2    0    0  154    2    1  966]]\n",
      "\n",
      "---\n",
      "\n",
      "test 06\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[433  11   0   0   0   0   4   0   0   2]\n",
      " [  0 422   0   0   0   0  28   0   0   0]\n",
      " [  0   0 447   0   0   0   3   0   0   0]\n",
      " [  0   0   0 445   0   0   5   0   0   0]\n",
      " [  0   0   0  10 426   0   0   0  14   0]\n",
      " [  0   0   0   0   0 348   0   0 102   0]\n",
      " [  0   0   0   0   0   0 450   0   0   0]\n",
      " [  0   0   0   0   0   0   0 450   0   0]\n",
      " [  0   0   0  16  23   0   1   0 410   0]\n",
      " [  0  15   0   0   0   0   6   0   0 429]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[141   3   0   0   0   0   1   0   0   5]\n",
      " [  0 145   0   0   0   0   5   0   0   0]\n",
      " [  0   0 150   0   0   0   0   0   0   0]\n",
      " [  0   0   0 150   0   0   0   0   0   0]\n",
      " [  0   0   0   1 145   0   0   0   4   0]\n",
      " [  0   0   0   0   0 117   0   0  33   0]\n",
      " [  0   0   0   0   0   0 150   0   0   0]\n",
      " [  0   0   0   0   0   0   1 149   0   0]\n",
      " [  0   0   0   6  11   0   0   0 133   0]\n",
      " [  0   6   0   0   0   0   1   0   0 143]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_03 = pickle.load(open('mlp_03.sav', 'rb'))\n",
    "\n",
    "print(\"test 01\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train_denoised) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test_denoised) * (-100)\n",
    "\n",
    "prediction = mlp_03.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_03.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 02\\n\")\n",
    "prediction = mlp_03.predict(x_out_train_denoised)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_03.predict(x_out_test_denoised)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 03\\n\")\n",
    "after_autoencoder_x_train = autoencoder_02.predict(ae_x_out_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_02.predict(ae_x_out_test_noisy) * (-100)\n",
    "\n",
    "prediction = mlp_03.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_03.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 04\\n\")\n",
    "after_autoencoder_x_train = autoencoder_03.predict(ae_x_in_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_03.predict(ae_x_in_test_noisy) * (-100)\n",
    "\n",
    "prediction = mlp_03.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_03.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 05\\n\")\n",
    "after_autoencoder_x_train = autoencoder_01.predict(ae_x_in_train_noisy)\n",
    "after_autoencoder_x_test = autoencoder_01.predict(ae_x_in_test_noisy)\n",
    "after_autoencoder_x_train = autoencoder_04.predict(after_autoencoder_x_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(after_autoencoder_x_test) * (-100)\n",
    "\n",
    "prediction = mlp_03.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_03.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"test 06\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test) * (-100)\n",
    "\n",
    "prediction = mlp_03.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_in_train, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_03.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_in_test, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 01\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4264  169    0    0    0    0   14    0    7   46]\n",
      " [ 130 3939   10    0    0    0  111    0   41  269]\n",
      " [   0    0 4492    0    0    0    0    0    8    0]\n",
      " [ 101   72    1 3988  313    0    0    0   25    0]\n",
      " [   0    0    0  339 3943   19    0    0  199    0]\n",
      " [   0    0    0    0    8 4362    0    0  130    0]\n",
      " [   0   45    0    0    0    0 4353    0   57   45]\n",
      " [   0    0    0    0    0    0   32 4468    0    0]\n",
      " [   0    0    4  245  165  263    4    0 3819    0]\n",
      " [   0  211    0    0    0    0    0    0    0 4289]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1423   60    0    0    0    0    6    0    2    9]\n",
      " [  48 1295    5    0    0    0   44    0   12   96]\n",
      " [   0    0 1498    0    0    0    0    0    2    0]\n",
      " [  38   23    1 1324  107    0    0    0    7    0]\n",
      " [   0    0    0  124 1312    3    0    0   61    0]\n",
      " [   0    0    0    0    2 1462    0    0   36    0]\n",
      " [   0   17    0    0    0    0 1451    0   20   12]\n",
      " [   0    0    0    0    0    0   16 1484    0    0]\n",
      " [   0    0    1   71   63   93    1    0 1271    0]\n",
      " [   0   56    0    0    0    0    0    0    0 1444]]\n",
      "\n",
      "---\n",
      "\n",
      "test 02\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4500    0    0    0    0    0    0    0    0    0]\n",
      " [   0 4401   99    0    0    0    0    0    0    0]\n",
      " [   0   14 4483    0    0    0    0    0    3    0]\n",
      " [   0    0    0 3107 1390    0    0    0    3    0]\n",
      " [   0    0    0  363 4133    2    0    0    2    0]\n",
      " [   0    0    0    0    0 4500    0    0    0    0]\n",
      " [   0    0    0    0    0    0 4455   45    0    0]\n",
      " [   0    0    0    0    0    0   29 4471    0    0]\n",
      " [   0    0   15  220    0    0    0    0 4265    0]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1500    0    0    0    0    0    0    0    0    0]\n",
      " [   0 1464   36    0    0    0    0    0    0    0]\n",
      " [   0    6 1491    0    0    0    0    0    3    0]\n",
      " [   0    0    0 1007  491    0    0    0    2    0]\n",
      " [   0    0    0  120 1379    0    0    0    1    0]\n",
      " [   0    0    0    0    0 1500    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1490   10    0    0]\n",
      " [   0    0    0    0    0    0   11 1489    0    0]\n",
      " [   0    0    4   65    0    0    0    0 1431    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]]\n",
      "\n",
      "---\n",
      "\n",
      "test 03\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4390   52    1    0    0    0    0    0    0   57]\n",
      " [  40 4295   19    0    0    0    0    0    0  146]\n",
      " [   0   19 4468    2    2    0    0    0    9    0]\n",
      " [   0    0    0 4367  128    4    0    0    1    0]\n",
      " [   0    0    8   99 4357   23    0    0   13    0]\n",
      " [   0    0    0    0   21 4479    0    0    0    0]\n",
      " [   0    0    0    0    0    0 4476   24    0    0]\n",
      " [   0    0    0    0    0    0   15 4485    0    0]\n",
      " [   0    0    5    7    0    0    0    0 4488    0]\n",
      " [ 207   22    0    0    0    0    0    0    0 4271]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1468   16    0    0    0    0    0    0    0   16]\n",
      " [  14 1423    6    0    0    0    0    0    0   57]\n",
      " [   0    6 1487    3    1    0    0    0    3    0]\n",
      " [   0    0    0 1454   43    3    0    0    0    0]\n",
      " [   0    0    5   26 1457    8    0    0    4    0]\n",
      " [   0    0    0    1   10 1489    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1493    7    0    0]\n",
      " [   0    0    0    0    0    0    5 1495    0    0]\n",
      " [   0    0    0    4    0    0    0    0 1496    0]\n",
      " [  63    4    0    0    0    0    0    0    0 1433]]\n",
      "\n",
      "---\n",
      "\n",
      "test 04\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   0    0    0    0    0    0 1989 2511    0    0]\n",
      " [   0    0    0    0    0    0 3491 1009    0    0]\n",
      " [   0    0    0    0    0    0 4420   80    0    0]\n",
      " [   0    0    0    0    0    0 3856  644    0    0]\n",
      " [   0    0    0    0    0    0 3171 1329    0    0]\n",
      " [   0    0    0    0    0    0 4350  150    0    0]\n",
      " [   0    0    0    0    0    0 4400  100    0    0]\n",
      " [   0    0    0    0    0    0 4499    1    0    0]\n",
      " [   0    0    0    0    0    0 3300 1200    0    0]\n",
      " [   0    0    0    0    0    0 4196  304    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0    0    0    0    0    0  653  847    0    0]\n",
      " [   0    0    0    0    0    0 1163  337    0    0]\n",
      " [   0    0    0    0    0    0 1479   21    0    0]\n",
      " [   0    0    0    0    0    0 1265  235    0    0]\n",
      " [   0    0    0    0    0    0 1047  453    0    0]\n",
      " [   0    0    0    0    0    0 1443   57    0    0]\n",
      " [   0    0    0    0    0    0 1472   28    0    0]\n",
      " [   0    0    0    0    0    0 1499    1    0    0]\n",
      " [   0    0    0    0    0    0 1128  372    0    0]\n",
      " [   0    0    0    0    0    0 1401   99    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 05\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[3237  482   31  183   46    0  377    0   53   91]\n",
      " [ 153 3090    2    7    1    0  709   84  118  336]\n",
      " [  14  121 3537    9    0    0  270   84   65  400]\n",
      " [ 398  117   51 3138  361    0  284    2  130   19]\n",
      " [ 276   25   17  827 2853   52   37    1  411    1]\n",
      " [   0    0    1  175   63 1619    4    0 2638    0]\n",
      " [ 138  348   96   31   14    0 3496  127   41  209]\n",
      " [   0  212  294    9    3    0 1165 2641   36  140]\n",
      " [ 182   99  135  940  317   65  354   53 2295   60]\n",
      " [ 287  566  412    6    0    0  370   11   22 2826]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1060  143    8   74   21    0  132    0   22   40]\n",
      " [  56 1005    2    4    0    0  255   31   34  113]\n",
      " [   3   36 1184    2    0    0   92   16   22  145]\n",
      " [ 144   43   17 1015  121    0  103    0   45   12]\n",
      " [  89    9    6  287  939   12    9    1  146    2]\n",
      " [   0    0    1   55   22  572    2    0  848    0]\n",
      " [  46  122   25   11    2    0 1167   48   11   68]\n",
      " [   0   65  110    2    1    0  411  864   14   33]\n",
      " [  61   23   46  318  110   17  104   25  776   20]\n",
      " [  71  203  117    2    0    0  140    2    7  958]]\n",
      "\n",
      "---\n",
      "\n",
      "test 06\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[433  11   0   0   0   0   0   0   0   6]\n",
      " [  0 422   0   0   0   0  28   0   0   0]\n",
      " [  0   0 447   0   0   0   1   0   2   0]\n",
      " [  0   0   0 325 112   0   4   0   9   0]\n",
      " [  0   0   0 166 270   0   0   0  14   0]\n",
      " [  0   0   0   0   0 348   0   0 102   0]\n",
      " [  0   0   0   0   0   0 450   0   0   0]\n",
      " [  0   0   0   0   0   0   3 447   0   0]\n",
      " [  0   0   0  39   0   0   1   0 410   0]\n",
      " [  0  16   2   0   0   0   6   0   0 426]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[141   3   0   0   0   0   1   0   0   5]\n",
      " [  0 145   0   0   0   0   5   0   0   0]\n",
      " [  0   0 150   0   0   0   0   0   0   0]\n",
      " [  0   0   0 102  44   0   0   0   4   0]\n",
      " [  0   0   0  54  92   0   0   0   4   0]\n",
      " [  0   0   0   0   0 117   0   0  33   0]\n",
      " [  0   0   0   0   0   0 150   0   0   0]\n",
      " [  0   0   0   0   0   0   3 147   0   0]\n",
      " [  0   0   0  17   0   0   0   0 133   0]\n",
      " [  0   6   1   0   0   0   1   0   0 142]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_04 = pickle.load(open('mlp_04.sav', 'rb'))\n",
    "\n",
    "print(\"test 01\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train_denoised) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test_denoised) * (-100)\n",
    "\n",
    "prediction = mlp_04.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_04.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 02\\n\")\n",
    "prediction = mlp_04.predict(x_out_train_denoised)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_04.predict(x_out_test_denoised)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 03\\n\")\n",
    "after_autoencoder_x_train = autoencoder_02.predict(ae_x_out_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_02.predict(ae_x_out_test_noisy) * (-100)\n",
    "\n",
    "prediction = mlp_04.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_04.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 04\\n\")\n",
    "after_autoencoder_x_train = autoencoder_03.predict(ae_x_in_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_03.predict(ae_x_in_test_noisy) * (-100)\n",
    "\n",
    "prediction = mlp_04.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_04.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 05\\n\")\n",
    "after_autoencoder_x_train = autoencoder_01.predict(ae_x_in_train_noisy)\n",
    "after_autoencoder_x_test = autoencoder_01.predict(ae_x_in_test_noisy)\n",
    "after_autoencoder_x_train = autoencoder_04.predict(after_autoencoder_x_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(after_autoencoder_x_test) * (-100)\n",
    "\n",
    "prediction = mlp_04.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_04.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"test 06\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test) * (-100)\n",
    "\n",
    "prediction = mlp_04.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_in_train, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = mlp_04.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_in_test, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
