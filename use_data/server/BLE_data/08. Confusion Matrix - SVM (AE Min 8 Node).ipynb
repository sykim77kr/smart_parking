{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix - SVM (AE Min 8 Node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"..\\\\..\\\\..\\\\data\\\\BLE_data\\\\\"\n",
    "def read_test_data(set_num, model_name, mode):\n",
    "    if model_name == 5:\n",
    "        raw_data = np.loadtxt(base_dir + \"raw_data\\\\in_\" + mode + \"_\" + str(set_num) + '.csv', delimiter=',', dtype=np.float32)\n",
    "    elif model_name == 6:\n",
    "        raw_data = np.loadtxt(base_dir + \"raw_data\\\\out_\" + mode + \"_\" + str(set_num) + '.csv', delimiter=',', dtype=np.float32)\n",
    "    b_data    = raw_data[:,0:3]\n",
    "    cell_data = raw_data[:,3:13]\n",
    "\n",
    "    return b_data, cell_data\n",
    "\n",
    "def read_denoised_test_data(set_num, model_name, mode):\n",
    "    if model_name == 5:\n",
    "        raw_data = np.loadtxt(base_dir + \"filtered_data\\\\in_\" + mode + \"_\" + str(set_num) + '_denoised.csv', delimiter=',', dtype=np.float32)\n",
    "    elif model_name == 6:\n",
    "        raw_data = np.loadtxt(base_dir + \"filtered_data\\\\out_\" + mode + \"_\" + str(set_num) + '_denoised.csv', delimiter=',', dtype=np.float32)\n",
    "    b_data    = raw_data[:,0:3]\n",
    "    cell_data = raw_data[:,3:13]\n",
    "\n",
    "    return b_data, cell_data\n",
    "\n",
    "def one_hot_convert_normal(data, end_line, output_num):\n",
    "    list_data = []\n",
    "\n",
    "    for row in range(0, end_line):\n",
    "        for column in range(0, output_num):\n",
    "            if data[row][column] == 1:\n",
    "                list_data.append(column + 1)\n",
    "    return list_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name: 5 (car_in) / 6 (car_out)\n",
    "# Car-in data\n",
    "model_name = 5\n",
    "set_num = 6000\n",
    "train_set_num = int(set_num * 0.75)\n",
    "test_set_num = int(set_num * 0.25)\n",
    "\n",
    "x_in_train_noisy, y_in_train_noisy = read_test_data(train_set_num, model_name, \"train\")\n",
    "x_in_train_denoised, y_in_train_denoised = read_denoised_test_data(train_set_num, model_name, \"train\")\n",
    "x_in_test_noisy, y_in_test_noisy = read_test_data(test_set_num, model_name, \"test\")\n",
    "x_in_test_denoised, y_in_test_denoised = read_denoised_test_data(test_set_num, model_name, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name: 5 (car_in) / 6 (car_out)\n",
    "# Car-out data\n",
    "model_name = 6\n",
    "set_num = 6000\n",
    "train_set_num = int(set_num * 0.75)\n",
    "test_set_num = int(set_num * 0.25)\n",
    "\n",
    "x_out_train_noisy, y_out_train_noisy = read_test_data(train_set_num, model_name, \"train\")\n",
    "x_out_train_denoised, y_out_train_denoised = read_denoised_test_data(train_set_num, model_name, \"train\")\n",
    "x_out_test_noisy, y_out_test_noisy = read_test_data(test_set_num, model_name, \"test\")\n",
    "x_out_test_denoised, y_out_test_denoised = read_denoised_test_data(test_set_num, model_name, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Car-in\n",
    "ae_x_in_train_noisy = x_in_train_noisy.astype('float32') / -100.\n",
    "ae_x_in_train_denoised = x_in_train_denoised.astype('float32') / -100.\n",
    "ae_x_in_test_noisy = x_in_test_noisy.astype('float32') / -100.\n",
    "ae_x_in_test_denoised = x_in_test_denoised.astype('float32') / -100.\n",
    "# Car-out\n",
    "ae_x_out_train_noisy = x_out_train_noisy.astype('float32') / -100.\n",
    "ae_x_out_train_denoised = x_out_train_denoised.astype('float32') / -100.\n",
    "ae_x_out_test_noisy = x_out_test_noisy.astype('float32') / -100.\n",
    "ae_x_out_test_denoised = x_out_test_denoised.astype('float32') / -100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "output_num = 10\n",
    "end_line = train_set_num * output_num\n",
    "\n",
    "oh_y_in_train_denoised = one_hot_convert_normal(y_in_train_denoised, end_line, output_num)\n",
    "oh_y_in_train_denoised = np.array(oh_y_in_train_denoised)\n",
    "\n",
    "oh_y_out_train_denoised = one_hot_convert_normal(y_out_train_denoised, end_line, output_num)\n",
    "oh_y_out_train_denoised = np.array(oh_y_out_train_denoised)\n",
    "\n",
    "# Testing data\n",
    "end_line = test_set_num * output_num\n",
    "\n",
    "oh_y_in_test_denoised = one_hot_convert_normal(y_in_test_denoised, end_line, output_num)\n",
    "oh_y_in_test_denoised = np.array(oh_y_in_test_denoised)\n",
    "\n",
    "oh_y_out_test_denoised = one_hot_convert_normal(y_out_test_denoised, end_line, output_num)\n",
    "oh_y_out_test_denoised = np.array(oh_y_out_test_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_01 = load_model('autoencoder_01.h5')\n",
    "autoencoder_02 = load_model('autoencoder_02.h5')\n",
    "autoencoder_03 = load_model('autoencoder_03.h5')\n",
    "autoencoder_04 = load_model('autoencoder_04.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ 방법 1 ]\n",
    "## 데이터 10개의 평균 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def average(x, y, set_num, data_num):\n",
    "    idx = 0\n",
    "    sum = np.array([0, 0, 0])\n",
    "    data = [[0 for col in range(3)] for row in range(int(set_num * 10 / data_num))]\n",
    "    label = [[0 for col in range(10)] for row in range(int(set_num * 10 / data_num))]\n",
    "    for i in range(set_num * 10):\n",
    "        for j in range(3):\n",
    "            sum[j] += x[i][j]\n",
    "        if(i % data_num == data_num - 1):\n",
    "            for j in range(3):\n",
    "                data[idx][j] = int(round(sum[j] / data_num))\n",
    "            for j in range(10):\n",
    "                label[idx][j] = y[i][j]\n",
    "            idx += 1\n",
    "            sum = np.array([0, 0, 0])    \n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_autoencoder_x_train = autoencoder_01.predict(ae_x_in_train_noisy) * (-100)\n",
    "x_train, y_train = average(after_autoencoder_x_train, y_in_train_noisy, 4500, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_autoencoder_x_test = autoencoder_01.predict(ae_x_in_test_noisy) * (-100)\n",
    "x_test, y_test = average(after_autoencoder_x_test, y_in_test_noisy, 1500, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "ae_x_in_train = x_train.astype('float32') / -100.\n",
    "ae_x_in_test = x_test.astype('float32') / -100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average data\n",
    "# Train data\n",
    "oh_y_in_train = one_hot_convert_normal(y_train, int(4500 * output_num / 10), output_num)\n",
    "oh_y_in_train = np.array(oh_y_in_train)\n",
    "\n",
    "# Test data\n",
    "oh_y_in_test = one_hot_convert_normal(y_test, int(1500 * output_num / 10), output_num)\n",
    "oh_y_in_test = np.array(oh_y_in_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 01\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4459    0    0    0    0    0   38    0    0    3]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1488    0    0    0    0    0   11    0    0    1]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 02\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 03\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1499    1    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 04\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[3612  222   16  132  131    7  120    2  116  142]\n",
      " [ 227 3835    7   20   20    1  107   53   41  189]\n",
      " [  10   23 3649   20    0  152  118  113  125  290]\n",
      " [ 314   71   34 3270  232   95  167   18  272   27]\n",
      " [ 264    8   13  181 3494  200   36   34  261    9]\n",
      " [   0    1  106   41   94 4060    6    2  174   16]\n",
      " [ 100  107  117   78    4    5 3497  389   30  173]\n",
      " [   2  141  297    8   11   25  412 3401   77  126]\n",
      " [ 192   72  309  281  382  575  175  119 2309   86]\n",
      " [ 166  226  334   24    6  132  251  109   55 3197]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1061  121    5   75   60    4   61    2   57   54]\n",
      " [ 112 1156    3   10    5    2   47   29   33  103]\n",
      " [   4    6 1187    3    0   55   46   35   45  119]\n",
      " [ 152   26   12  975   99   34   68    8   98   28]\n",
      " [  96    7    8   89 1046   73   19   15  137   10]\n",
      " [   1    1   45   14   37 1315    1    2   69   15]\n",
      " [  54   37   50   44    4    0 1062  141   17   91]\n",
      " [   4   52  117    6    4    8  161 1075   36   37]\n",
      " [  81   23  124  140  153  224   60   48  624   23]\n",
      " [  90  120  139   21    4   37  114   52   25  898]]\n",
      "\n",
      "---\n",
      "\n",
      "test 05\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [4498    0    0    0    0    0    2    0    0    0]\n",
      " [4481    0    0    0    0    0   19    0    0    0]\n",
      " [4499    0    0    0    0    0    1    0    0    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1494    0    0    0    0    0    6    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 06\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[450   0   0   0   0   0   0   0   0   0]\n",
      " [450   0   0   0   0   0   0   0   0   0]\n",
      " [450   0   0   0   0   0   0   0   0   0]\n",
      " [450   0   0   0   0   0   0   0   0   0]\n",
      " [450   0   0   0   0   0   0   0   0   0]\n",
      " [450   0   0   0   0   0   0   0   0   0]\n",
      " [450   0   0   0   0   0   0   0   0   0]\n",
      " [422   0   0   0   0   0  28   0   0   0]\n",
      " [450   0   0   0   0   0   0   0   0   0]\n",
      " [450   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[150   0   0   0   0   0   0   0   0   0]\n",
      " [150   0   0   0   0   0   0   0   0   0]\n",
      " [150   0   0   0   0   0   0   0   0   0]\n",
      " [150   0   0   0   0   0   0   0   0   0]\n",
      " [150   0   0   0   0   0   0   0   0   0]\n",
      " [150   0   0   0   0   0   0   0   0   0]\n",
      " [150   0   0   0   0   0   0   0   0   0]\n",
      " [141   0   0   0   0   0   9   0   0   0]\n",
      " [150   0   0   0   0   0   0   0   0   0]\n",
      " [150   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_01 = pickle.load(open('svc_01.sav', 'rb'))\n",
    "\n",
    "print(\"test 01\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train_denoised) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test_denoised) * (-100)\n",
    "\n",
    "prediction = svc_01.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_01.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 02\\n\")\n",
    "prediction = svc_01.predict(x_out_train_denoised)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_01.predict(x_out_test_denoised)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 03\\n\")\n",
    "after_autoencoder_x_train = autoencoder_02.predict(ae_x_out_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_02.predict(ae_x_out_test_noisy) * (-100)\n",
    "\n",
    "prediction = svc_01.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_01.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 04\\n\")\n",
    "after_autoencoder_x_train = autoencoder_03.predict(ae_x_in_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_03.predict(ae_x_in_test_noisy) * (-100)\n",
    "\n",
    "prediction = svc_01.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_01.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 05\\n\")\n",
    "after_autoencoder_x_train = autoencoder_01.predict(ae_x_in_train_noisy)\n",
    "after_autoencoder_x_test = autoencoder_01.predict(ae_x_in_test_noisy)\n",
    "after_autoencoder_x_train = autoencoder_04.predict(after_autoencoder_x_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(after_autoencoder_x_test) * (-100)\n",
    "\n",
    "prediction = svc_01.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_01.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"test 06\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test) * (-100)\n",
    "\n",
    "prediction = svc_01.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_in_train, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_01.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_in_test, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 01\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4384   75    0   11    0    0   30    0    0    0]\n",
      " [  28 4273    0    0    0    0   84    0    0  115]\n",
      " [   0    0 4500    0    0    0    0    0    0    0]\n",
      " [ 140    0    0 4262   85    0    0    0   13    0]\n",
      " [   0    0    0   44 4261   19    0    0  176    0]\n",
      " [   0    0    0    0    3 4373    0    0  124    0]\n",
      " [   7   69    0    0    0    0 4424    0    0    0]\n",
      " [   0    0    0    0    0    0    0 4500    0    0]\n",
      " [   0    0    6   69  220  161    0    4 4040    0]\n",
      " [   0  202    0    0    0    0    0    0    0 4298]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1460   11    0    9    0    0    7    0   13    0]\n",
      " [  12 1406    0    0    0    0   30    0   10   42]\n",
      " [   0    0 1500    0    0    0    0    0    0    0]\n",
      " [  49    0    0 1402   39    0    0    0   10    0]\n",
      " [   0    0    0   16 1416    3    0    0   65    0]\n",
      " [   0    0    0    0    2 1448    0    0   50    0]\n",
      " [   1   24    0    0    0    0 1472    0    3    0]\n",
      " [   0    0    0    0    0    0    0 1499    1    0]\n",
      " [   0    0    2   23   90   51    0    0 1334    0]\n",
      " [   0   54    0    0    0    0    0    0    2 1444]]\n",
      "\n",
      "---\n",
      "\n",
      "test 02\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[  39    0    0    0    0    0    0    0 4461    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]\n",
      " [   0    0    0    0   68    0    0    0 4432    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[  17    0    0    0    0    0    0    0 1483    0]\n",
      " [   0    0    0    0    0    0    0    0 1500    0]\n",
      " [   0    0    0    0    0    0    0    0 1500    0]\n",
      " [   0    0    0    0    0    0    0    0 1500    0]\n",
      " [   0    0    0    0   14    0    0    0 1486    0]\n",
      " [   0    0    0    0    0    0    0    0 1500    0]\n",
      " [   0    0    0    0    0    0    0    0 1500    0]\n",
      " [   0    0    0    0    0    0    0    0 1500    0]\n",
      " [   0    0    0    0    0    0    0    0 1500    0]\n",
      " [   0    0    0    0    0    0    0    0 1500    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 03\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[2318   15    0    0    0    0    0    0 2164    3]\n",
      " [   2 3101    1    0    0    0    0    0 1358   38]\n",
      " [   0    4 4006    0    0    0    0    0  490    0]\n",
      " [   0    0    0 4151   19    2    0    0  328    0]\n",
      " [   0    0    0   13 3697    1    0    0  789    0]\n",
      " [   0    0    0    0    6 3951    0    0  543    0]\n",
      " [   0    0    0    0    0    0 3994    0  506    0]\n",
      " [   0    0    0    0    0    0    2 2989 1509    0]\n",
      " [   0    0    0    1    0    0    0    0 4499    0]\n",
      " [  13   14    0    0    0    0    0    0 3448 1025]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[ 754    3    0    0    0    0    0    0  741    2]\n",
      " [   0 1028    0    0    0    0    0    0  452   20]\n",
      " [   0    1 1340    0    0    0    0    0  159    0]\n",
      " [   0    0    0 1373    5    0    0    0  122    0]\n",
      " [   0    0    3    2 1243    1    0    0  251    0]\n",
      " [   0    0    0    0    0 1303    0    0  197    0]\n",
      " [   0    0    0    0    0    0 1325    0  175    0]\n",
      " [   0    0    0    0    0    0    1  967  532    0]\n",
      " [   0    0    0    1    0    0    0    0 1499    0]\n",
      " [   6    4    0    0    0    0    0    0 1154  336]]\n",
      "\n",
      "---\n",
      "\n",
      "test 04\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   0    0    0    0    0    0    0    6 4494    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]\n",
      " [   0    0    0    0    0    0    0    1 4499    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0    0    0    0    0    0    0    1 1499    0]\n",
      " [   0    0    0    0    0    0    0    0 1500    0]\n",
      " [   0    0    0    0    0    0    0    0 1500    0]\n",
      " [   0    0    0    0    0    0    0    0 1500    0]\n",
      " [   0    0    0    0    0    0    0    0 1500    0]\n",
      " [   0    0    0    0    0    0    0    0 1500    0]\n",
      " [   0    0    0    0    0    0    0    0 1500    0]\n",
      " [   0    0    0    0    0    0    0    0 1500    0]\n",
      " [   0    0    0    0    0    0    0    0 1500    0]\n",
      " [   0    0    0    0    0    0    0    0 1500    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 05\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[2481   57    8   78    3    0   63    0 1752   58]\n",
      " [  97 2582    2    8    0    0   85   72 1389  265]\n",
      " [   8   30 3015    2    0    0  109   41 1015  280]\n",
      " [ 171    5    1 2762   77    0  102    0 1379    3]\n",
      " [ 107    0    0  160 1320    0   20    1 2892    0]\n",
      " [   0    0    0   53   23    3    2    0 4419    0]\n",
      " [  50   47   40   26    0    0 2397  101 1733  106]\n",
      " [   0  134  208    5    0    0  840 2376  848   89]\n",
      " [ 100   15   86  226  114    0  144   39 3743   33]\n",
      " [ 197  197  223    0    0    0  141    7 1356 2379]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[ 789   14    2   26    3    0   21    0  619   26]\n",
      " [  35  867    1    3    0    0   50   23  434   87]\n",
      " [   2    9 1025    0    0    0   38    8  313  105]\n",
      " [  71    7    1  912   22    0   38    0  444    5]\n",
      " [  31    0    1   53  430    0    4    1  980    0]\n",
      " [   0    0    0   12   12    2    2    0 1472    0]\n",
      " [  18    6   14    3    0    0  798   40  590   31]\n",
      " [   0   45   83    1    0    0  301  777  275   18]\n",
      " [  35    2   33   83   36    1   59   19 1223    9]\n",
      " [  55   76   60    0    0    0   48    0  470  791]]\n",
      "\n",
      "---\n",
      "\n",
      "test 06\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[421  22   0   3   0   0   4   0   0   0]\n",
      " [  0 423   0   0   0   0  27   0   0   0]\n",
      " [  0   0 442   0   0   0   0   0   8   0]\n",
      " [  0   0   0 438   0   0   5   0   7   0]\n",
      " [  0   0   0   7 381   0   0   0  62   0]\n",
      " [  0   0   0   0   0 406   0   0  44   0]\n",
      " [  0   0   0   0   0   0 450   0   0   0]\n",
      " [  0   0   0   0   0   0   0 450   0   0]\n",
      " [  0   0   0  19  41   0   2   0 388   0]\n",
      " [  0 113   0   0   0   0   4   0   8 325]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[142   6   0   1   0   0   1   0   0   0]\n",
      " [  0 145   0   0   0   0   5   0   0   0]\n",
      " [  0   0 148   0   0   0   0   0   2   0]\n",
      " [  0   0   0 148   0   0   0   0   2   0]\n",
      " [  0   0   0   1 129   0   0   0  20   0]\n",
      " [  0   0   0   0   0 131   0   0  19   0]\n",
      " [  0   0   0   0   0   0 150   0   0   0]\n",
      " [  0   0   0   0   0   0   1 149   0   0]\n",
      " [  0   0   0   5  19   0   0   0 126   0]\n",
      " [  0  33   0   0   0   0   1   0   1 115]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_02 = pickle.load(open('svc_02.sav', 'rb'))\n",
    "\n",
    "print(\"test 01\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train_denoised) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test_denoised) * (-100)\n",
    "\n",
    "prediction = svc_02.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_02.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 02\\n\")\n",
    "prediction = svc_02.predict(x_out_train_denoised)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_02.predict(x_out_test_denoised)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 03\\n\")\n",
    "after_autoencoder_x_train = autoencoder_02.predict(ae_x_out_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_02.predict(ae_x_out_test_noisy) * (-100)\n",
    "\n",
    "prediction = svc_02.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_02.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 04\\n\")\n",
    "after_autoencoder_x_train = autoencoder_03.predict(ae_x_in_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_03.predict(ae_x_in_test_noisy) * (-100)\n",
    "\n",
    "prediction = svc_02.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_02.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 05\\n\")\n",
    "after_autoencoder_x_train = autoencoder_01.predict(ae_x_in_train_noisy)\n",
    "after_autoencoder_x_test = autoencoder_01.predict(ae_x_in_test_noisy)\n",
    "after_autoencoder_x_train = autoencoder_04.predict(after_autoencoder_x_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(after_autoencoder_x_test) * (-100)\n",
    "\n",
    "prediction = svc_02.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_02.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"test 06\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test) * (-100)\n",
    "\n",
    "prediction = svc_02.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_in_train, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_02.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_in_test, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 01\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[2437   44    0    0    0    0    0    0    0 2019]\n",
      " [  41 3522    0    0    0    0    0    0    0  937]\n",
      " [   0  129 3273    0    5    0    0    0    0 1093]\n",
      " [   0  113    0  972   62    0    0    0    7 3346]\n",
      " [   0   89    0  193 1811    9    0    0    1 2397]\n",
      " [   0  126    0    0   13 1495    0    0    0 2866]\n",
      " [   0   11    0    0    0    0  818    0    0 3671]\n",
      " [   0   57    0    0    0    0    0  802    0 3641]\n",
      " [   0    3    0   17   26   14    0    0 1136 3304]\n",
      " [  23  351    0    0    0    0    0    0    0 4126]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[ 785   11    0    0    0    0    0    0    0  704]\n",
      " [  23 1173    0    0    0    0    0    0    0  304]\n",
      " [   0   42 1074    0    1    0    0    0    0  383]\n",
      " [   0   30    0  349   42    0    0    0    4 1075]\n",
      " [   0   39    0   51  613    3    0    0    0  794]\n",
      " [   0   33    0    0    4  466    0    0    0  997]\n",
      " [   0    3    0    0    0    0  245    0    0 1252]\n",
      " [   0   11    0    0    0    0    0  270    0 1219]\n",
      " [   0    2    0    5   10    1    0    0  346 1136]\n",
      " [   8  108    0    0    0    0    0    0    0 1384]]\n",
      "\n",
      "---\n",
      "\n",
      "test 02\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[  49    0    0    0    0    0    0    0    0 4451]\n",
      " [   4  137    0    0    0    0    0    0    0 4359]\n",
      " [   0    0   24    0    0    0    0    0    0 4476]\n",
      " [   0    0    0   31    0    0    0    0    0 4469]\n",
      " [   0    0    0    0  160    0    0    0    0 4340]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0    0    0    0    0    0  439    0    0 4061]\n",
      " [   0    0    0    0    0    0    0  191    0 4309]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[  27    0    0    0    0    0    0    0    0 1473]\n",
      " [   0   37    0    0    0    0    0    0    0 1463]\n",
      " [   0    0    5    0    0    0    0    0    0 1495]\n",
      " [   0    0    0   14    0    0    0    0    0 1486]\n",
      " [   0    0    0    0   52    0    0    0    0 1448]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0    0    0    0    0    0  149    0    0 1351]\n",
      " [   0    0    0    0    0    0    0   77    0 1423]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]]\n",
      "\n",
      "---\n",
      "\n",
      "test 03\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4420   30    0    0    0    0    0    0    0   50]\n",
      " [   6 4399    3    0    0    0    0    0    0   92]\n",
      " [   0   16 4483    0    1    0    0    0    0    0]\n",
      " [   0    0    0 4483   13    4    0    0    0    0]\n",
      " [   0    0    0   19 4476    5    0    0    0    0]\n",
      " [   0    0    0    0   11 4489    0    0    0    0]\n",
      " [   0    0    0    0    0    0 4493    7    0    0]\n",
      " [   0    0    0    0    0    0    7 4493    0    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]\n",
      " [ 112   14    0    0    0    0    0    0    0 4374]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1440    7    1    0    0    0    0    0    0   52]\n",
      " [  10 1423    4    0    0    0    0    0    0   63]\n",
      " [   0    6 1462    0    0    0    0    0    0   32]\n",
      " [   0    0    0 1473   15    3    0    0    0    9]\n",
      " [   0    0    2   13 1459    6    0    0    0   20]\n",
      " [   0    0    0    1    2 1488    0    0    0    9]\n",
      " [   0    0    0    0    0    0 1488    5    0    7]\n",
      " [   0    0    0    0    0    0    5 1484    0   11]\n",
      " [   0    0    0    1    0    0    0    0 1483   16]\n",
      " [  48   14    0    0    0    0    0    0    0 1438]]\n",
      "\n",
      "---\n",
      "\n",
      "test 04\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   0    0    0    0    0    0    0    3    0 4497]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0    0    0    0    0    0    0    4    0 1496]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]]\n",
      "\n",
      "---\n",
      "\n",
      "test 05\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[2166  128    3   12    8    0    3    0    0 2180]\n",
      " [  90 2720    1    0    0    0    9    2    0 1678]\n",
      " [   9  179 2321    1   10    0   36   12   16 1916]\n",
      " [ 139   41    0  292   10    0   33    1    2 3982]\n",
      " [  65   69    0   64  189    0   10    0    2 4101]\n",
      " [   0    1    0   33    0    0    2    0   13 4451]\n",
      " [  47  113    2    6    1    0  861   24    0 3446]\n",
      " [   0  182  125    0    2    0  353  205    6 3627]\n",
      " [  70   50   47   99    5    0   48    5   80 4096]\n",
      " [ 172  464   76    0    4    0   27    0    0 3757]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[ 696   50    0    1    1    0    1    0    0  751]\n",
      " [  32  907    0    0    0    0    2    1    0  558]\n",
      " [   1   59  788    0    2    0   15    3    1  631]\n",
      " [  48   12    0  118    3    0   12    1    0 1306]\n",
      " [  21   21    0   16   57    0    2    0    0 1383]\n",
      " [   0    1    0    8    0    0    1    0    5 1485]\n",
      " [  18   37    0    1    1    0  288   10    0 1145]\n",
      " [   0   55   40    0    0    0  131   76    0 1198]\n",
      " [  29    9   22   41    4    0   17    3   34 1341]\n",
      " [  51  161   28    0    2    0    9    3    0 1246]]\n",
      "\n",
      "---\n",
      "\n",
      "test 06\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[136   5   0   0   0   0   0   0   0 309]\n",
      " [  0 347   0   0   0   0   0   0   0 103]\n",
      " [  0  41 229   0   0   0   0   0   0 180]\n",
      " [  0   0   0  81   2   0   0   0   0 367]\n",
      " [  0   0   0   2   0   0   0   0   0 448]\n",
      " [  0   0   0   0   0   3   0   0   0 447]\n",
      " [  0   0   0   0   0   0 143   0   0 307]\n",
      " [  0   0   0   0   0   0   0  77   0 373]\n",
      " [  0   0   0   0   0   0   0   0  16 434]\n",
      " [  0 112   0   0   0   0   0   0   0 338]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[ 39   2   0   0   0   0   0   0   0 109]\n",
      " [  0 115   0   0   0   0   0   0   0  35]\n",
      " [  0  14  70   0   0   0   0   0   0  66]\n",
      " [  0   0   0  31   1   0   0   0   0 118]\n",
      " [  0   0   0   0   0   0   0   0   0 150]\n",
      " [  0   0   0   0   0   2   0   0   0 148]\n",
      " [  0   0   0   0   0   0  48   0   0 102]\n",
      " [  0   0   0   0   0   0   0  30   0 120]\n",
      " [  0   0   0   0   0   0   0   0   2 148]\n",
      " [  0  36   0   0   0   0   0   0   0 114]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_03 = pickle.load(open('svc_03.sav', 'rb'))\n",
    "\n",
    "print(\"test 01\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train_denoised) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test_denoised) * (-100)\n",
    "\n",
    "prediction = svc_03.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_03.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 02\\n\")\n",
    "prediction = svc_03.predict(x_out_train_denoised)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_03.predict(x_out_test_denoised)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 03\\n\")\n",
    "after_autoencoder_x_train = autoencoder_02.predict(ae_x_out_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_02.predict(ae_x_out_test_noisy) * (-100)\n",
    "\n",
    "prediction = svc_03.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_03.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 04\\n\")\n",
    "after_autoencoder_x_train = autoencoder_03.predict(ae_x_in_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_03.predict(ae_x_in_test_noisy) * (-100)\n",
    "\n",
    "prediction = svc_03.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_03.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 05\\n\")\n",
    "after_autoencoder_x_train = autoencoder_01.predict(ae_x_in_train_noisy)\n",
    "after_autoencoder_x_test = autoencoder_01.predict(ae_x_in_test_noisy)\n",
    "after_autoencoder_x_train = autoencoder_04.predict(after_autoencoder_x_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(after_autoencoder_x_test) * (-100)\n",
    "\n",
    "prediction = svc_03.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_03.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"test 06\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test) * (-100)\n",
    "\n",
    "prediction = svc_03.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_in_train, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_03.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_in_test, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 01\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[  83   44 4373    0    0    0    0    0    0    0]\n",
      " [   4 3999  497    0    0    0    0    0    0    0]\n",
      " [   0    0 4500    0    0    0    0    0    0    0]\n",
      " [   0    4 4490    0    6    0    0    0    0    0]\n",
      " [   0    0 4313    0  187    0    0    0    0    0]\n",
      " [   0    0 4500    0    0    0    0    0    0    0]\n",
      " [   0   18 4482    0    0    0    0    0    0    0]\n",
      " [   0    0 4500    0    0    0    0    0    0    0]\n",
      " [   0    0 4486    0    6    0    0    0    8    0]\n",
      " [   0  340 4160    0    0    0    0    0    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[  18   13 1469    0    0    0    0    0    0    0]\n",
      " [   0 1327  173    0    0    0    0    0    0    0]\n",
      " [   0    0 1500    0    0    0    0    0    0    0]\n",
      " [   0    0 1498    0    2    0    0    0    0    0]\n",
      " [   0    0 1435    0   65    0    0    0    0    0]\n",
      " [   0    0 1500    0    0    0    0    0    0    0]\n",
      " [   0    5 1495    0    0    0    0    0    0    0]\n",
      " [   0    0 1500    0    0    0    0    0    0    0]\n",
      " [   0    0 1496    0    1    0    0    0    3    0]\n",
      " [   0  103 1397    0    0    0    0    0    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 02\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4500    0    0    0    0    0    0    0    0    0]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0    0 4500    0    0    0    0    0    0    0]\n",
      " [   0    0    0 4500    0    0    0    0    0    0]\n",
      " [   0    0    0    0 4500    0    0    0    0    0]\n",
      " [   0    0    0    0    0 4500    0    0    0    0]\n",
      " [   0    0    0    0    0    0 4500    0    0    0]\n",
      " [   0    0    0    0    0    0    0 4500    0    0]\n",
      " [   0    0    0    0    0    0    0    0 4500    0]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1497    0    3    0    0    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1500    0    0    0    0    0    0    0]\n",
      " [   0    0    6 1494    0    0    0    0    0    0]\n",
      " [   0    0   13    0 1487    0    0    0    0    0]\n",
      " [   0    0    0    0    0 1500    0    0    0    0]\n",
      " [   0    0    1    0    0    0 1499    0    0    0]\n",
      " [   0    0    0    0    0    0    0 1500    0    0]\n",
      " [   0    0   12    0    0    0    0    0 1488    0]\n",
      " [   0    0    1    0    0    0    0    0    0 1499]]\n",
      "\n",
      "---\n",
      "\n",
      "test 03\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[  26   50 4423    0    0    0    0    0    0    1]\n",
      " [   0 4317  183    0    0    0    0    0    0    0]\n",
      " [   0   12 4488    0    0    0    0    0    0    0]\n",
      " [   0    0 4499    1    0    0    0    0    0    0]\n",
      " [   0    0 4498    0    2    0    0    0    0    0]\n",
      " [   0    0 4500    0    0    0    0    0    0    0]\n",
      " [   0    0 4492    0    0    0    8    0    0    0]\n",
      " [   0    0 4495    0    0    0    0    5    0    0]\n",
      " [   0    0 4497    0    0    0    0    0    3    0]\n",
      " [   0   55 4423    0    0    0    0    0    0   22]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[  11   15 1473    0    0    0    0    0    0    1]\n",
      " [   0 1432   68    0    0    0    0    0    0    0]\n",
      " [   0    4 1496    0    0    0    0    0    0    0]\n",
      " [   0    0 1500    0    0    0    0    0    0    0]\n",
      " [   0    0 1498    0    2    0    0    0    0    0]\n",
      " [   0    0 1499    0    1    0    0    0    0    0]\n",
      " [   0    0 1494    0    0    0    6    0    0    0]\n",
      " [   0    0 1500    0    0    0    0    0    0    0]\n",
      " [   0    0 1500    0    0    0    0    0    0    0]\n",
      " [   0   12 1478    0    0    0    0    0    0   10]]\n",
      "\n",
      "---\n",
      "\n",
      "test 04\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   0    0 4496    0    0    0    0    4    0    0]\n",
      " [   0    0 4500    0    0    0    0    0    0    0]\n",
      " [   0    0 4499    0    0    0    0    1    0    0]\n",
      " [   0    0 4500    0    0    0    0    0    0    0]\n",
      " [   0    0 4500    0    0    0    0    0    0    0]\n",
      " [   0    0 4500    0    0    0    0    0    0    0]\n",
      " [   0    0 4500    0    0    0    0    0    0    0]\n",
      " [   0    0 4500    0    0    0    0    0    0    0]\n",
      " [   0    0 4500    0    0    0    0    0    0    0]\n",
      " [   0    0 4498    0    0    0    0    2    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0    0 1499    0    0    0    0    1    0    0]\n",
      " [   0    0 1500    0    0    0    0    0    0    0]\n",
      " [   0    0 1500    0    0    0    0    0    0    0]\n",
      " [   0    0 1500    0    0    0    0    0    0    0]\n",
      " [   0    0 1500    0    0    0    0    0    0    0]\n",
      " [   0    0 1500    0    0    0    0    0    0    0]\n",
      " [   0    0 1500    0    0    0    0    0    0    0]\n",
      " [   0    0 1500    0    0    0    0    0    0    0]\n",
      " [   0    0 1499    0    0    0    0    1    0    0]\n",
      " [   0    0 1500    0    0    0    0    0    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 05\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   3  314 4182    1    0    0    0    0    0    0]\n",
      " [   0 2994 1506    0    0    0    0    0    0    0]\n",
      " [   0   74 4426    0    0    0    0    0    0    0]\n",
      " [   0   30 4459    4    7    0    0    0    0    0]\n",
      " [   0    1 4472    7   20    0    0    0    0    0]\n",
      " [   0    0 4473    0    2    0    1    0   24    0]\n",
      " [   1  228 4271    0    0    0    0    0    0    0]\n",
      " [   0  203 4297    0    0    0    0    0    0    0]\n",
      " [   0   50 4421    2   11    0    3    0   13    0]\n",
      " [   0  574 3926    0    0    0    0    0    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0  100 1399    1    0    0    0    0    0    0]\n",
      " [   0  979  520    0    0    0    0    0    0    1]\n",
      " [   0   28 1472    0    0    0    0    0    0    0]\n",
      " [   0   12 1482    3    3    0    0    0    0    0]\n",
      " [   0    0 1491    1    8    0    0    0    0    0]\n",
      " [   0    0 1495    0    0    0    0    0    5    0]\n",
      " [   0   77 1423    0    0    0    0    0    0    0]\n",
      " [   0   60 1440    0    0    0    0    0    0    0]\n",
      " [   0   15 1477    1    3    0    0    0    4    0]\n",
      " [   0  185 1315    0    0    0    0    0    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 06\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[ 22   7 421   0   0   0   0   0   0   0]\n",
      " [  0 391  59   0   0   0   0   0   0   0]\n",
      " [  0   0 450   0   0   0   0   0   0   0]\n",
      " [  0   0 450   0   0   0   0   0   0   0]\n",
      " [  0   0 447   0   3   0   0   0   0   0]\n",
      " [  0   0 450   0   0   0   0   0   0   0]\n",
      " [  0   0 450   0   0   0   0   0   0   0]\n",
      " [  0   0 450   0   0   0   0   0   0   0]\n",
      " [  0   0 450   0   0   0   0   0   0   0]\n",
      " [  0  56 394   0   0   0   0   0   0   0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[  7   2 141   0   0   0   0   0   0   0]\n",
      " [  0 132  18   0   0   0   0   0   0   0]\n",
      " [  0   0 150   0   0   0   0   0   0   0]\n",
      " [  0   0 150   0   0   0   0   0   0   0]\n",
      " [  0   0 150   0   0   0   0   0   0   0]\n",
      " [  0   0 150   0   0   0   0   0   0   0]\n",
      " [  0   0 150   0   0   0   0   0   0   0]\n",
      " [  0   0 150   0   0   0   0   0   0   0]\n",
      " [  0   0 150   0   0   0   0   0   0   0]\n",
      " [  0  19 131   0   0   0   0   0   0   0]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_04 = pickle.load(open('svc_04.sav', 'rb'))\n",
    "\n",
    "print(\"test 01\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train_denoised) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test_denoised) * (-100)\n",
    "\n",
    "prediction = svc_04.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_04.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 02\\n\")\n",
    "prediction = svc_04.predict(x_out_train_denoised)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_04.predict(x_out_test_denoised)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 03\\n\")\n",
    "after_autoencoder_x_train = autoencoder_02.predict(ae_x_out_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_02.predict(ae_x_out_test_noisy) * (-100)\n",
    "\n",
    "prediction = svc_04.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_04.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 04\\n\")\n",
    "after_autoencoder_x_train = autoencoder_03.predict(ae_x_in_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_03.predict(ae_x_in_test_noisy) * (-100)\n",
    "\n",
    "prediction = svc_04.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_04.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 05\\n\")\n",
    "after_autoencoder_x_train = autoencoder_01.predict(ae_x_in_train_noisy)\n",
    "after_autoencoder_x_test = autoencoder_01.predict(ae_x_in_test_noisy)\n",
    "after_autoencoder_x_train = autoencoder_04.predict(after_autoencoder_x_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(after_autoencoder_x_test) * (-100)\n",
    "\n",
    "prediction = svc_04.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_04.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"test 06\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test) * (-100)\n",
    "\n",
    "prediction = svc_04.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_in_train, prediction)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = svc_04.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_in_test, prediction)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
