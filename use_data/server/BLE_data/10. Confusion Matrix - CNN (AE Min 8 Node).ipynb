{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix - CNN (AE Min 8 Node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"..\\\\..\\\\..\\\\data\\\\BLE_data\\\\\"\n",
    "def read_test_data(set_num, model_name, mode):\n",
    "    if model_name == 5:\n",
    "        raw_data = np.loadtxt(base_dir + \"raw_data\\\\in_\" + mode + \"_\" + str(set_num) + '.csv', delimiter=',', dtype=np.float32)\n",
    "    elif model_name == 6:\n",
    "        raw_data = np.loadtxt(base_dir + \"raw_data\\\\out_\" + mode + \"_\" + str(set_num) + '.csv', delimiter=',', dtype=np.float32)\n",
    "    b_data    = raw_data[:,0:3]\n",
    "    cell_data = raw_data[:,3:13]\n",
    "\n",
    "    return b_data, cell_data\n",
    "\n",
    "def read_denoised_test_data(set_num, model_name, mode):\n",
    "    if model_name == 5:\n",
    "        raw_data = np.loadtxt(base_dir + \"filtered_data\\\\in_\" + mode + \"_\" + str(set_num) + '_denoised.csv', delimiter=',', dtype=np.float32)\n",
    "    elif model_name == 6:\n",
    "        raw_data = np.loadtxt(base_dir + \"filtered_data\\\\out_\" + mode + \"_\" + str(set_num) + '_denoised.csv', delimiter=',', dtype=np.float32)\n",
    "    b_data    = raw_data[:,0:3]\n",
    "    cell_data = raw_data[:,3:13]\n",
    "\n",
    "    return b_data, cell_data\n",
    "\n",
    "def one_hot_convert_normal(data, end_line, output_num):\n",
    "    list_data = []\n",
    "\n",
    "    for row in range(0, end_line):\n",
    "        for column in range(0, output_num):\n",
    "            if data[row][column] == 1:\n",
    "                list_data.append(column + 1)\n",
    "    return list_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name: 5 (car_in) / 6 (car_out)\n",
    "# Car-in data\n",
    "model_name = 5\n",
    "set_num = 6000\n",
    "train_set_num = int(set_num * 0.75)\n",
    "test_set_num = int(set_num * 0.25)\n",
    "\n",
    "x_in_train_noisy, y_in_train_noisy = read_test_data(train_set_num, model_name, \"train\")\n",
    "x_in_train_denoised, y_in_train_denoised = read_denoised_test_data(train_set_num, model_name, \"train\")\n",
    "x_in_test_noisy, y_in_test_noisy = read_test_data(test_set_num, model_name, \"test\")\n",
    "x_in_test_denoised, y_in_test_denoised = read_denoised_test_data(test_set_num, model_name, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name: 5 (car_in) / 6 (car_out)\n",
    "# Car-out data\n",
    "model_name = 6\n",
    "set_num = 6000\n",
    "train_set_num = int(set_num * 0.75)\n",
    "test_set_num = int(set_num * 0.25)\n",
    "\n",
    "x_out_train_noisy, y_out_train_noisy = read_test_data(train_set_num, model_name, \"train\")\n",
    "x_out_train_denoised, y_out_train_denoised = read_denoised_test_data(train_set_num, model_name, \"train\")\n",
    "x_out_test_noisy, y_out_test_noisy = read_test_data(test_set_num, model_name, \"test\")\n",
    "x_out_test_denoised, y_out_test_denoised = read_denoised_test_data(test_set_num, model_name, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Car-in\n",
    "ae_x_in_train_noisy = x_in_train_noisy.astype('float32') / -100.\n",
    "ae_x_in_train_denoised = x_in_train_denoised.astype('float32') / -100.\n",
    "ae_x_in_test_noisy = x_in_test_noisy.astype('float32') / -100.\n",
    "ae_x_in_test_denoised = x_in_test_denoised.astype('float32') / -100.\n",
    "# Car-out\n",
    "ae_x_out_train_noisy = x_out_train_noisy.astype('float32') / -100.\n",
    "ae_x_out_train_denoised = x_out_train_denoised.astype('float32') / -100.\n",
    "ae_x_out_test_noisy = x_out_test_noisy.astype('float32') / -100.\n",
    "ae_x_out_test_denoised = x_out_test_denoised.astype('float32') / -100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Car-in\n",
    "x_in_train_noisy = x_in_train_noisy.reshape(45000, 3, 1)\n",
    "x_in_train_denoised = x_in_train_denoised.reshape(45000, 3, 1)\n",
    "x_in_test_noisy = x_in_test_noisy.reshape(15000, 3, 1)\n",
    "x_in_test_denoised = x_in_test_denoised.reshape(15000, 3, 1)\n",
    "# Car-out\n",
    "x_out_train_noisy = x_out_train_noisy.reshape(45000, 3, 1)\n",
    "x_out_train_denoised = x_out_train_denoised.reshape(45000, 3, 1)\n",
    "x_out_test_noisy = x_out_test_noisy.reshape(15000, 3, 1)\n",
    "x_out_test_denoised = x_out_test_denoised.reshape(15000, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "output_num = 10\n",
    "end_line = train_set_num * output_num\n",
    "\n",
    "oh_y_in_train_denoised = one_hot_convert_normal(y_in_train_denoised, end_line, output_num)\n",
    "oh_y_in_train_denoised = np.array(oh_y_in_train_denoised)\n",
    "\n",
    "oh_y_out_train_denoised = one_hot_convert_normal(y_out_train_denoised, end_line, output_num)\n",
    "oh_y_out_train_denoised = np.array(oh_y_out_train_denoised)\n",
    "\n",
    "# Testing data\n",
    "end_line = test_set_num * output_num\n",
    "\n",
    "oh_y_in_test_denoised = one_hot_convert_normal(y_in_test_denoised, end_line, output_num)\n",
    "oh_y_in_test_denoised = np.array(oh_y_in_test_denoised)\n",
    "\n",
    "oh_y_out_test_denoised = one_hot_convert_normal(y_out_test_denoised, end_line, output_num)\n",
    "oh_y_out_test_denoised = np.array(oh_y_out_test_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_01 = load_model('autoencoder_01.h5')\n",
    "autoencoder_02 = load_model('autoencoder_02.h5')\n",
    "autoencoder_03 = load_model('autoencoder_03.h5')\n",
    "autoencoder_04 = load_model('autoencoder_04.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ 방법 1 ]\n",
    "## 데이터 10개의 평균 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def average(x, y, set_num, data_num):\n",
    "    idx = 0\n",
    "    sum = np.array([0, 0, 0])\n",
    "    data = [[0 for col in range(3)] for row in range(int(set_num * 10 / data_num))]\n",
    "    label = [[0 for col in range(10)] for row in range(int(set_num * 10 / data_num))]\n",
    "    for i in range(set_num * 10):\n",
    "        for j in range(3):\n",
    "            sum[j] += x[i][j]\n",
    "        if(i % data_num == data_num - 1):\n",
    "            for j in range(3):\n",
    "                data[idx][j] = int(round(sum[j] / data_num))\n",
    "            for j in range(10):\n",
    "                label[idx][j] = y[i][j]\n",
    "            idx += 1\n",
    "            sum = np.array([0, 0, 0])    \n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_autoencoder_x_train = autoencoder_01.predict(ae_x_in_train_noisy) * (-100)\n",
    "x_train, y_train = average(after_autoencoder_x_train, y_in_train_noisy, 4500, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_autoencoder_x_test = autoencoder_01.predict(ae_x_in_test_noisy) * (-100)\n",
    "x_test, y_test = average(after_autoencoder_x_test, y_in_test_noisy, 1500, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "ae_x_in_train = x_train.astype('float32') / -100.\n",
    "ae_x_in_test = x_test.astype('float32') / -100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average data\n",
    "# Train data\n",
    "oh_y_in_train = one_hot_convert_normal(y_train, int(4500 * output_num / 10), output_num)\n",
    "oh_y_in_train = np.array(oh_y_in_train)\n",
    "\n",
    "# Test data\n",
    "oh_y_in_test = one_hot_convert_normal(y_test, int(1500 * output_num / 10), output_num)\n",
    "oh_y_in_test = np.array(oh_y_in_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_01\n",
      "\n",
      "test 01\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0 4461    0    0    0    0   16   10    0   13]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0  174    0    0    0    0    0    0    0 4326]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [ 104  581    0  684    0    0 2812  273    0   46]\n",
      " [4486    0    0    0    0    0    5    0    0    9]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1479    0    0    0    0    4    8    0    9]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0   61    0    0    0    0    0    0    0 1439]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [  34  212    0  224    0    0  921   95    0   14]\n",
      " [1492    0    0    0    0    0    2    0    0    6]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 02\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   0 4500    0    0    0    0    0    0    0    0]\n",
      " [   0 4441    0    0    0    0    0    0    0   59]\n",
      " [   0   14    0    0    0    0    0    0    0 4486]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [2019  194    0  211    0   30  846 1164   36    0]\n",
      " [4500    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1483    0    0    0    0    0    0    0   17]\n",
      " [   0    6    0    0    0    0    0    0    0 1494]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [ 700   74    0   60    0   13  266  375   12    0]\n",
      " [1500    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 03\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   0 4499    0    0    0    0    0    0    0    1]\n",
      " [   0 4488    0    0    0    0    0    0    0   12]\n",
      " [   0   26    0    0    0    0    0    0    0 4474]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [ 219    0    0 1246    0    0 3027    8    0    0]\n",
      " [4495    0    0    3    0    0    1    1    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]\n",
      " [   0 4500    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0 1500    0    0    0    0    0    0    0    0]\n",
      " [   0 1494    0    0    0    0    0    0    0    6]\n",
      " [   0    7    0    0    0    0    0    0    0 1493]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [  64    0    0  445    0    0  987    4    0    0]\n",
      " [1497    0    0    2    0    0    1    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]\n",
      " [   0 1500    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 04\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[3241    0   90  469    0   73  227  353    0   47]\n",
      " [1209    0  718  168    0   47   83 1456    0  819]\n",
      " [ 177    0 1196  524    0  674  975  927    0   27]\n",
      " [ 936    0  563  543    0  294 1059 1083    0   22]\n",
      " [1573    0  139  322    0  212  234 1073    0  947]\n",
      " [ 201    0  419  236    0 1964  379 1301    0    0]\n",
      " [ 292    0  785  601    0  616 1395  803    0    8]\n",
      " [   7    0  702   36    0  539  407 2803    0    6]\n",
      " [1486    0  280  479    0  574  384 1293    0    4]\n",
      " [ 540    0  307  429    0  254  394 1483    0 1093]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1085    0   22  164    0   24   81  104    0   20]\n",
      " [ 408    0  246   59    0   14   28  450    0  295]\n",
      " [  44    0  428  167    0  223  346  285    0    7]\n",
      " [ 327    0  181  176    0   91  362  358    0    5]\n",
      " [ 535    0   39  118    0  107   88  317    0  296]\n",
      " [  79    0  139   73    0  633  123  453    0    0]\n",
      " [  85    0  276  214    0  184  478  260    0    3]\n",
      " [   1    0  242   14    0  183  134  926    0    0]\n",
      " [ 456    0  101  195    0  226  116  404    0    2]\n",
      " [ 184    0   94  163    0   90  134  468    0  367]]\n",
      "\n",
      "---\n",
      "\n",
      "test 05\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   6 4121    0    0    0    0   63   46    0  264]\n",
      " [  87 4232    0    2    0    0   68  100    0   11]\n",
      " [ 139  594    0   28    0    0  103   25    0 3611]\n",
      " [  10  643    0   10    0    0  144   27    0 3666]\n",
      " [   3  318    0    5    0    0   18    0    0 4156]\n",
      " [   0    0    0    0    0    0    3    1    0 4496]\n",
      " [ 195 1076    0  274    0    0 2623  186    0  146]\n",
      " [2716  407    0  119    0    0  873   44    0  341]\n",
      " [  75  430    0   34    0    0  196   17    0 3748]\n",
      " [  22 3844    0   10    0    0  147   60    0  417]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0 1360    0    2    0    0   14   16    0  108]\n",
      " [  34 1387    0    1    0    0   33   39    0    6]\n",
      " [  36  200    0   10    0    0   36   10    0 1208]\n",
      " [   3  242    0    6    0    0   48    9    0 1192]\n",
      " [   1  103    0    0    0    0    6    0    0 1390]\n",
      " [   0    0    0    1    0    0    1    0    0 1498]\n",
      " [  73  377    0   95    0    0  845   69    0   41]\n",
      " [ 887  116    0   44    0    0  307   18    0  128]\n",
      " [  33  134    0    6    0    0   63    0    0 1264]\n",
      " [   7 1288    0    6    0    0   54   26    0  119]]\n",
      "\n",
      "---\n",
      "\n",
      "test 06\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[  0 450   0   0   0   0   0   0   0   0]\n",
      " [  0 428   0   0   0   0   3  19   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0 449]\n",
      " [  0   1   0   0   0   0   0   0   0 449]\n",
      " [  0   0   0   0   0   0   0   0   0 450]\n",
      " [  0   0   0   0   0   0   0   0   0 450]\n",
      " [  0   1   0 109   0   0 340   0   0   0]\n",
      " [450   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0 449]\n",
      " [  0 447   0   0   0   0   1   0   0   2]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[  0 150   0   0   0   0   0   0   0   0]\n",
      " [  0 146   0   0   0   0   1   3   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 150]\n",
      " [  0   0   0   0   0   0   0   0   0 150]\n",
      " [  0   0   0   0   0   0   0   0   0 150]\n",
      " [  0   0   0   0   0   0   0   0   0 150]\n",
      " [  0   0   0  42   0   0 108   0   0   0]\n",
      " [149   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 150]\n",
      " [  0 149   0   0   0   0   0   0   0   1]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_01 = load_model('cnn_01.h5')\n",
    "\n",
    "print(\"cnn_01\\n\")\n",
    "\n",
    "print(\"test 01\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train_denoised) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test_denoised) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(45000, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(15000, 3, 1)\n",
    "\n",
    "prediction = cnn_01.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_01.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 02\\n\")\n",
    "prediction = cnn_01.predict(x_out_train_denoised)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_01.predict(x_out_test_denoised)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 03\\n\")\n",
    "after_autoencoder_x_train = autoencoder_02.predict(ae_x_out_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_02.predict(ae_x_out_test_noisy) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(45000, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(15000, 3, 1)\n",
    "\n",
    "prediction = cnn_01.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_01.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 04\\n\")\n",
    "after_autoencoder_x_train = autoencoder_03.predict(ae_x_in_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_03.predict(ae_x_in_test_noisy) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(45000, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(15000, 3, 1)\n",
    "\n",
    "prediction = cnn_01.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_01.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 05\\n\")\n",
    "after_autoencoder_x_train = autoencoder_01.predict(ae_x_in_train_noisy)\n",
    "after_autoencoder_x_test = autoencoder_01.predict(ae_x_in_test_noisy)\n",
    "after_autoencoder_x_train = autoencoder_04.predict(after_autoencoder_x_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(after_autoencoder_x_test) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(45000, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(15000, 3, 1)\n",
    "\n",
    "prediction = cnn_01.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_01.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 06\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(4500, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(1500, 3, 1)\n",
    "\n",
    "prediction = cnn_01.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_in_train, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_01.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_in_test, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_02\n",
      "\n",
      "test 01\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4348   71   14    0    0    0   39    0    0   28]\n",
      " [ 138 3892   10    0    0    0  150    0    0  310]\n",
      " [   0    0 4492    0    0    0    0    0    8    0]\n",
      " [ 157   11    6 4173  137    0    0    0   16    0]\n",
      " [   0    0    0   50 4168   20    0    0  262    0]\n",
      " [   0    0    0    0    0 4312    0    0  188    0]\n",
      " [   0   45    0    0    0    0 4436    0   13    6]\n",
      " [   0    0    0    0    0    0   32 4468    0    0]\n",
      " [   0    0    4   52  274  191    4    0 3975    0]\n",
      " [   0  117    0    0    0    0    0    0    0 4383]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1449   22   11    0    0    0   10    0    0    8]\n",
      " [  52 1269    5    0    0    0   52    0    0  122]\n",
      " [   0    0 1498    0    0    0    0    0    2    0]\n",
      " [  54    4    4 1383   49    0    0    0    6    0]\n",
      " [   0    0    0   12 1387    4    0    0   97    0]\n",
      " [   0    0    0    0    0 1447    0    0   53    0]\n",
      " [   0   16    0    0    0    0 1477    0    5    2]\n",
      " [   0    0    0    0    0    0   16 1484    0    0]\n",
      " [   0    0    1   20   94   76    1    0 1308    0]\n",
      " [   0   23    0    0    0    0    0    0    0 1477]]\n",
      "\n",
      "---\n",
      "\n",
      "test 02\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4491    0    0    0    0    0    0    0    0    9]\n",
      " [  21 4374  101    0    0    0    0    0    0    4]\n",
      " [   0   37 4462    1    0    0    0    0    0    0]\n",
      " [   0    0    0 2949 1546    0    0    0    5    0]\n",
      " [   0    0    0 1460 2981   15    0    0   44    0]\n",
      " [   0    0    0    0    0 4500    0    0    0    0]\n",
      " [   0    0    0    0    0    0 4323  177    0    0]\n",
      " [   0    0    0    0    0    0   29 4471    0    0]\n",
      " [   0   64  127  235    0    0    0    0 4074    0]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1497    0    0    0    0    0    0    0    0    3]\n",
      " [   5 1458   37    0    0    0    0    0    0    0]\n",
      " [   0   11 1487    2    0    0    0    0    0    0]\n",
      " [   0    0    0  984  512    0    0    0    4    0]\n",
      " [   0    0    0  501  981    4    0    0   14    0]\n",
      " [   0    0    0    0    0 1500    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1454   46    0    0]\n",
      " [   0    0    0    0    0    0   11 1489    0    0]\n",
      " [   0   36   40   68    0    0    0    0 1356    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]]\n",
      "\n",
      "---\n",
      "\n",
      "test 03\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4344   46    1    0    0    0    0    0    0  109]\n",
      " [  33 4275   14    0    0    0    0    0    0  178]\n",
      " [   0   16 4471    2    0    0    0    0   11    0]\n",
      " [   0    0    0 4450   45    4    0    0    1    0]\n",
      " [   0    0    8  126 4320   33    0    0   13    0]\n",
      " [   0    0    0    0   17 4481    0    0    2    0]\n",
      " [   0    0    0    0    0    0 4475   25    0    0]\n",
      " [   0    0    0    0    0    0   15 4485    0    0]\n",
      " [   0    0    6    4    2    0    0    0 4488    0]\n",
      " [ 158   11    0    0    0    0    0    0    0 4331]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1458   14    0    0    0    0    0    0    0   28]\n",
      " [   9 1415    5    0    0    0    0    0    0   71]\n",
      " [   0    5 1487    2    1    1    0    0    4    0]\n",
      " [   0    0    0 1481   15    3    0    0    1    0]\n",
      " [   0    0    5   41 1441    9    0    0    4    0]\n",
      " [   0    0    0    0    9 1491    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1492    8    0    0]\n",
      " [   0    0    0    0    0    0    5 1495    0    0]\n",
      " [   0    0    0    3    1    0    0    0 1496    0]\n",
      " [  48    3    0    0    0    0    0    0    0 1449]]\n",
      "\n",
      "---\n",
      "\n",
      "test 04\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   0    0    0    0    0    0 1495 3005    0    0]\n",
      " [   0    0    0    0    0    0 3357 1143    0    0]\n",
      " [   0    0    0    0    0    0 4363  137    0    0]\n",
      " [   0    0    0    0    0    0 3666  834    0    0]\n",
      " [   0    0    0    0    0    0 3017 1483    0    0]\n",
      " [   0    0    0    0    0    0 4331  169    0    0]\n",
      " [   0    0    0    0    0    0 4318  182    0    0]\n",
      " [   0    0    0    0    0    0 4496    4    0    0]\n",
      " [   0    0    0    0    0    0 3118 1382    0    0]\n",
      " [   0    0    0    0    0    0 4065  435    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0    0    0    0    0    0  488 1012    0    0]\n",
      " [   0    0    0    0    0    0 1115  384    1    0]\n",
      " [   0    0    0    0    0    0 1466   34    0    0]\n",
      " [   0    0    0    0    0    0 1204  296    0    0]\n",
      " [   0    0    0    0    0    0  995  505    0    0]\n",
      " [   0    0    0    0    0    0 1434   66    0    0]\n",
      " [   0    0    0    0    0    0 1441   59    0    0]\n",
      " [   0    0    0    0    0    0 1499    1    0    0]\n",
      " [   0    0    0    0    0    0 1076  424    0    0]\n",
      " [   0    0    0    0    0    0 1349  151    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 05\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[3313  348   32  193   43    0  442    0    9  120]\n",
      " [ 166 2952    2    8    0    0  844   85    1  442]\n",
      " [  14  131 3508    5    3    0  272   84   51  432]\n",
      " [ 441   56   60 3167  333    0  301    2  125   15]\n",
      " [ 291    7   15  375 3237   43   38    1  491    2]\n",
      " [   0    0    1   94  114 1171    4    0 3116    0]\n",
      " [ 158  275  102   47    0    0 3558  127    3  230]\n",
      " [   0  209  288    8    4    0 1168 2645   26  152]\n",
      " [ 198   64  134  584  600   34  374   53 2392   67]\n",
      " [ 315  418  408    3    3    0  400   11    2 2940]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1087  105    8   84   13    0  158    0    4   41]\n",
      " [  57  963    2    4    0    0  291   31    0  152]\n",
      " [   3   46 1174    2    0    0   94   16   13  152]\n",
      " [ 161   16   19 1042   97    0  114    0   37   14]\n",
      " [  96    1    6  138 1062   10   10    1  175    1]\n",
      " [   0    0    1   31   39  420    2    0 1007    0]\n",
      " [  51  102   26   13    0    0 1186   48    1   73]\n",
      " [   1   68  105    2    1    0  415  865    7   36]\n",
      " [  63   15   49  193  221   12  108   25  790   24]\n",
      " [  82  157  115    2    0    0  149    2    1  992]]\n",
      "\n",
      "---\n",
      "\n",
      "test 06\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[436   8   0   0   0   0   4   0   0   2]\n",
      " [  0 422   0   0   0   0  28   0   0   0]\n",
      " [  0   2 447   0   0   0   1   0   0   0]\n",
      " [  0   0   0 445   0   0   5   0   0   0]\n",
      " [  0   0   0  10 422   0   0   0  18   0]\n",
      " [  0   0   0   0   0 341   0   0 109   0]\n",
      " [  0   0   0   0   0   0 450   0   0   0]\n",
      " [  0   0   0   0   0   0   3 447   0   0]\n",
      " [  0   0   0  16  23   0   1   0 410   0]\n",
      " [  0  13   2   0   0   0   6   0   0 429]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[142   2   0   0   0   0   1   0   0   5]\n",
      " [  0 145   0   0   0   0   5   0   0   0]\n",
      " [  0   0 150   0   0   0   0   0   0   0]\n",
      " [  0   0   0 150   0   0   0   0   0   0]\n",
      " [  0   0   0   1 144   0   0   0   5   0]\n",
      " [  0   0   0   0   0 110   0   0  40   0]\n",
      " [  0   0   0   0   0   0 150   0   0   0]\n",
      " [  0   0   0   0   0   0   3 147   0   0]\n",
      " [  0   0   0   6  11   0   0   0 133   0]\n",
      " [  0   5   1   0   0   0   1   0   0 143]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_02 = load_model('cnn_02.h5')\n",
    "\n",
    "print(\"cnn_02\\n\")\n",
    "\n",
    "print(\"test 01\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train_denoised) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test_denoised) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(45000, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(15000, 3, 1)\n",
    "\n",
    "prediction = cnn_02.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_02.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 02\\n\")\n",
    "prediction = cnn_02.predict(x_out_train_denoised)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_02.predict(x_out_test_denoised)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 03\\n\")\n",
    "after_autoencoder_x_train = autoencoder_02.predict(ae_x_out_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_02.predict(ae_x_out_test_noisy) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(45000, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(15000, 3, 1)\n",
    "\n",
    "prediction = cnn_02.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_02.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 04\\n\")\n",
    "after_autoencoder_x_train = autoencoder_03.predict(ae_x_in_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_03.predict(ae_x_in_test_noisy) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(45000, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(15000, 3, 1)\n",
    "\n",
    "prediction = cnn_02.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_02.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 05\\n\")\n",
    "after_autoencoder_x_train = autoencoder_01.predict(ae_x_in_train_noisy)\n",
    "after_autoencoder_x_test = autoencoder_01.predict(ae_x_in_test_noisy)\n",
    "after_autoencoder_x_train = autoencoder_04.predict(after_autoencoder_x_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(after_autoencoder_x_test) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(45000, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(15000, 3, 1)\n",
    "\n",
    "prediction = cnn_02.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_02.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 06\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(4500, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(1500, 3, 1)\n",
    "\n",
    "prediction = cnn_02.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_in_train, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_02.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_in_test, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_03\n",
      "\n",
      "test 01\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4007  423   14    0    0    0   28    0    0   28]\n",
      " [ 109 3939   10    0    0    0  150    0    0  292]\n",
      " [   0    0 4492    0    0    0    0    0    8    0]\n",
      " [  47  121    6 4130  180    0    0    0   16    0]\n",
      " [   0    0    0   45 4264   32    0    0  159    0]\n",
      " [   0    0    0    0   12 4338    0    0  150    0]\n",
      " [   0   47    0    0    0    0 4432    0   13    8]\n",
      " [   0    0    0    0    0    0   32 4468    0    0]\n",
      " [   0    0    4   44  397  249    4    0 3802    0]\n",
      " [   0  177    0    0    0    0    0    0    0 4323]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1337  137   11    0    0    0    8    0    0    7]\n",
      " [  38 1292    5    0    0    0   52    0    0  113]\n",
      " [   0    0 1498    0    0    0    0    0    2    0]\n",
      " [  15   43    4 1371   61    0    0    0    6    0]\n",
      " [   0    0    0   12 1426    8    0    0   54    0]\n",
      " [   0    0    0    0    5 1455    0    0   40    0]\n",
      " [   0   18    0    0    0    0 1475    0    5    2]\n",
      " [   0    0    0    0    0    0   16 1484    0    0]\n",
      " [   0    0    1   17  127   90    1    0 1264    0]\n",
      " [   0   49    0    0    0    0    0    0    0 1451]]\n",
      "\n",
      "---\n",
      "\n",
      "test 02\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[3962    0    3    0    0    0    0    0    0  535]\n",
      " [   0 4393  107    0    0    0    0    0    0    0]\n",
      " [   0   32 4468    0    0    0    0    0    0    0]\n",
      " [   0    0    0 2403 2096    0    0    0    1    0]\n",
      " [   0    0    0 1445 2928  125    0    0    2    0]\n",
      " [   0    0    0    0    0 4500    0    0    0    0]\n",
      " [   0    0    0    0    0    0 4380  120    0    0]\n",
      " [   0    0    0    0    0    0   29 4471    0    0]\n",
      " [   0   46  217  202   33    0    0    0 4002    0]\n",
      " [   0    0    0    0    0    0    0    0    0 4500]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1325    0    0    0    0    0    0    0    0  175]\n",
      " [   0 1463   37    0    0    0    0    0    0    0]\n",
      " [   0   10 1490    0    0    0    0    0    0    0]\n",
      " [   0    0    0  797  701    0    0    0    2    0]\n",
      " [   0    0    0  495  954   50    0    0    1    0]\n",
      " [   0    0    0    0    0 1500    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1467   33    0    0]\n",
      " [   0    0    0    0    0    0   11 1489    0    0]\n",
      " [   0   25   74   62    6    0    0    0 1333    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]]\n",
      "\n",
      "---\n",
      "\n",
      "test 03\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4304   66    1    0    0    0    0    0    0  129]\n",
      " [  25 4302   14    0    0    0    0    0    0  159]\n",
      " [   0   16 4471    0    4    0    0    0    9    0]\n",
      " [   0    0    0 4422   73    4    0    0    1    0]\n",
      " [   0    0   10   83 4362   36    0    0    9    0]\n",
      " [   0    0    0    0   17 4483    0    0    0    0]\n",
      " [   0    0    0    0    0    0 4476   24    0    0]\n",
      " [   0    0    0    0    0    0   15 4485    0    0]\n",
      " [   0    0    6    3    4    0    0    0 4487    0]\n",
      " [ 120   20    0    0    0    0    0    0    0 4360]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1438   17    0    0    0    0    0    0    0   45]\n",
      " [   5 1423    5    0    0    0    0    0    0   67]\n",
      " [   0    5 1488    0    3    1    0    0    3    0]\n",
      " [   0    0    0 1469   28    3    0    0    0    0]\n",
      " [   0    0    5   23 1457   11    0    0    4    0]\n",
      " [   0    0    0    0    9 1491    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1492    8    0    0]\n",
      " [   0    0    0    0    0    0    5 1495    0    0]\n",
      " [   0    0    0    2    2    0    0    0 1496    0]\n",
      " [  39    4    0    0    0    0    0    0    0 1457]]\n",
      "\n",
      "---\n",
      "\n",
      "test 04\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   0    0    0    0    0    0 1635 2865    0    0]\n",
      " [   0    0    0    0    0    0 3392 1108    0    0]\n",
      " [   0    0    0    0    0    0 4387  113    0    0]\n",
      " [   0    0    0    0    0    0 3717  783    0    0]\n",
      " [   0    0    0    0    0    0 3068 1432    0    0]\n",
      " [   0    0    0    0    0    0 4333  167    0    0]\n",
      " [   0    0    0    0    0    0 4351  149    0    0]\n",
      " [   0    0    0    0    0    0 4498    2    0    0]\n",
      " [   0    0    0    0    0    0 3163 1337    0    0]\n",
      " [   0    0    0    0    0    7 4116  377    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0    0    0    0    0    0  535  965    0    0]\n",
      " [   0    0    0    0    0    1 1132  367    0    0]\n",
      " [   0    0    0    0    0    0 1473   27    0    0]\n",
      " [   0    0    0    0    0    0 1221  279    0    0]\n",
      " [   0    0    0    0    0    0 1017  483    0    0]\n",
      " [   0    0    0    0    0    0 1436   64    0    0]\n",
      " [   0    0    0    0    0    0 1451   49    0    0]\n",
      " [   0    0    0    0    0    0 1499    1    0    0]\n",
      " [   0    0    0    0    0    0 1091  409    0    0]\n",
      " [   0    0    0    0    0    2 1363  135    0    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 05\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[3019  677   42  176   61    0  428    0    5   92]\n",
      " [ 143 3068    2    8    0    0  832   85    1  361]\n",
      " [  14  153 3513    5    4    0  272   84   50  405]\n",
      " [ 320  168   77 3119  394    0  300    2  108   12]\n",
      " [ 191  106   16  354 3346   49   38    1  397    2]\n",
      " [   0    0    1   93  148 1461    4    0 2793    0]\n",
      " [ 115  358  104   46    0    0 3555  127    3  192]\n",
      " [   0  217  289    8    4    0 1169 2645   25  143]\n",
      " [ 159  114  142  502  783   59  374   53 2258   56]\n",
      " [ 256  578  408    3    3    0  396   11    2 2843]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[ 970  230   11   79   17    0  155    0    3   35]\n",
      " [  49 1004    2    4    0    0  290   31    0  120]\n",
      " [   3   50 1177    1    1    0   95   16   12  145]\n",
      " [ 113   62   24 1031  109    0  114    0   35   12]\n",
      " [  65   29   10  134 1097   11   10    1  142    1]\n",
      " [   0    0    1   30   52  509    2    0  906    0]\n",
      " [  36  125   28   11    2    0 1184   48    1   65]\n",
      " [   0   67  109    2    1    0  415  865    7   34]\n",
      " [  55   26   50  164  268   16  108   25  768   20]\n",
      " [  70  204  115    2    0    0  149    2    1  957]]\n",
      "\n",
      "---\n",
      "\n",
      "test 06\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[426  18   0   0   0   0   4   0   0   2]\n",
      " [  0 422   0   0   0   0  28   0   0   0]\n",
      " [  0   2 447   0   0   0   1   0   0   0]\n",
      " [  0   0   0 445   0   0   5   0   0   0]\n",
      " [  0   0   0  10 427   0   0   0  13   0]\n",
      " [  0   0   0   0   0 348   0   0 102   0]\n",
      " [  0   0   0   0   0   0 450   0   0   0]\n",
      " [  0   0   0   0   0   0   3 447   0   0]\n",
      " [  0   0   0  16  26   0   1   0 407   0]\n",
      " [  0  16   2   0   0   0   6   0   0 426]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[139   5   0   0   0   0   1   0   0   5]\n",
      " [  0 145   0   0   0   0   5   0   0   0]\n",
      " [  0   0 150   0   0   0   0   0   0   0]\n",
      " [  0   0   0 150   0   0   0   0   0   0]\n",
      " [  0   0   0   1 145   0   0   0   4   0]\n",
      " [  0   0   0   0   0 117   0   0  33   0]\n",
      " [  0   0   0   0   0   0 150   0   0   0]\n",
      " [  0   0   0   0   0   0   3 147   0   0]\n",
      " [  0   0   0   6  11   0   0   0 133   0]\n",
      " [  0   6   1   0   0   0   1   0   0 142]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_03 = load_model('cnn_03.h5')\n",
    "\n",
    "print(\"cnn_03\\n\")\n",
    "\n",
    "print(\"test 01\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train_denoised) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test_denoised) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(45000, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(15000, 3, 1)\n",
    "\n",
    "prediction = cnn_03.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_03.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 02\\n\")\n",
    "prediction = cnn_03.predict(x_out_train_denoised)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_03.predict(x_out_test_denoised)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 03\\n\")\n",
    "after_autoencoder_x_train = autoencoder_02.predict(ae_x_out_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_02.predict(ae_x_out_test_noisy) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(45000, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(15000, 3, 1)\n",
    "\n",
    "prediction = cnn_03.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_03.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 04\\n\")\n",
    "after_autoencoder_x_train = autoencoder_03.predict(ae_x_in_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_03.predict(ae_x_in_test_noisy) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(45000, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(15000, 3, 1)\n",
    "\n",
    "prediction = cnn_03.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_03.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 05\\n\")\n",
    "after_autoencoder_x_train = autoencoder_01.predict(ae_x_in_train_noisy)\n",
    "after_autoencoder_x_test = autoencoder_01.predict(ae_x_in_test_noisy)\n",
    "after_autoencoder_x_train = autoencoder_04.predict(after_autoencoder_x_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(after_autoencoder_x_test) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(45000, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(15000, 3, 1)\n",
    "\n",
    "prediction = cnn_03.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_03.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 06\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(4500, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(1500, 3, 1)\n",
    "\n",
    "prediction = cnn_03.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_in_train, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_03.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_in_test, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_04\n",
      "\n",
      "test 01\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[3937  514    0    0    0    0   39    0    0   10]\n",
      " [  94 4035   10    0    0    0  155    0    0  206]\n",
      " [   0    0 4492    0    0    0    0    0    8    0]\n",
      " [  35  138    1 4228   79    0    0    0   19    0]\n",
      " [   0    0    0  570 3624   20    0    0  286    0]\n",
      " [   0    0    0    0    6 4356    0    0  138    0]\n",
      " [   0   50    0    0    0    0 4432    0   17    1]\n",
      " [   0    0    0    0    0    0   79 4421    0    0]\n",
      " [   0    0    4  206  108  262    4    0 3916    0]\n",
      " [   0  282    0    0    0    0    0    0    0 4218]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1314  173    0    0    0    0   10    0    0    3]\n",
      " [  34 1338    5    0    0    0   57    0    0   66]\n",
      " [   0    0 1498    0    0    0    0    0    2    0]\n",
      " [  11   50    1 1394   37    0    0    0    7    0]\n",
      " [   0    0    0  194 1202    4    0    0  100    0]\n",
      " [   0    0    0    0    2 1459    0    0   39    0]\n",
      " [   0   17    0    0    0    0 1474    0    8    1]\n",
      " [   0    0    0    0    0    0   29 1471    0    0]\n",
      " [   0    0    1   73   39   92    1    0 1294    0]\n",
      " [   0   75    0    0    0    0    0    0    0 1425]]\n",
      "\n",
      "---\n",
      "\n",
      "test 02\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4500    0    0    0    0    0    0    0    0    0]\n",
      " [   0 4455   45    0    0    0    0    0    0    0]\n",
      " [   0   18 4482    0    0    0    0    0    0    0]\n",
      " [   0    0    0 4374  121    0    0    0    5    0]\n",
      " [   0    0    0  788 3681   28    0    0    3    0]\n",
      " [   0    0    0    0    0 4500    0    0    0    0]\n",
      " [   0    0    0    0    0    0 4459   41    0    0]\n",
      " [   0    0    0    0    0    0  191 4309    0    0]\n",
      " [   0    0   30   33    0    0    0    0 4437    0]\n",
      " [   4    0    0    0    0    0    0    0    0 4496]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1500    0    0    0    0    0    0    0    0    0]\n",
      " [   0 1485   15    0    0    0    0    0    0    0]\n",
      " [   0    6 1494    0    0    0    0    0    0    0]\n",
      " [   0    0    0 1446   50    0    0    0    4    0]\n",
      " [   0    0    0  277 1211    9    0    0    3    0]\n",
      " [   0    0    0    0    0 1500    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1492    8    0    0]\n",
      " [   0    0    0    0    0    0   71 1429    0    0]\n",
      " [   0    0    9    6    0    0    0    0 1485    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1500]]\n",
      "\n",
      "---\n",
      "\n",
      "test 03\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[4382   68    1    0    0    0    0    0    0   49]\n",
      " [  44 4330   13    0    0    0    0    0    0  113]\n",
      " [   0   20 4464    2    2    0    0    0   12    0]\n",
      " [   0    0    0 4447   47    4    0    0    2    0]\n",
      " [   0    0    7  132 4320   26    0    0   15    0]\n",
      " [   0    0    0    0   17 4483    0    0    0    0]\n",
      " [   0    0    0    0    0    0 4483   17    0    0]\n",
      " [   0    0    0    0    0    0   18 4482    0    0]\n",
      " [   0    0    5    6    0    0    0    0 4489    0]\n",
      " [ 237   42    0    0    0    0    0    0    0 4221]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[1470   19    0    0    0    0    0    0    0   11]\n",
      " [  13 1430    5    0    0    0    0    0    0   52]\n",
      " [   0    6 1485    3    0    1    0    0    5    0]\n",
      " [   0    0    0 1481   15    3    0    0    1    0]\n",
      " [   0    0    5   38 1444    9    0    0    4    0]\n",
      " [   0    0    0    1    8 1491    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1495    5    0    0]\n",
      " [   0    0    0    0    0    0    5 1495    0    0]\n",
      " [   0    0    0    3    0    0    0    0 1497    0]\n",
      " [  69    8    0    0    0    0    0    0    0 1423]]\n",
      "\n",
      "---\n",
      "\n",
      "test 04\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[   0    0    0    0    0    0 2748 1752    0    0]\n",
      " [   0    0    0    0    0    0 3851  649    0    0]\n",
      " [   0    0    0    0    0    0 4497    3    0    0]\n",
      " [   0    0    0    0    0    0 4207  293    0    0]\n",
      " [   0    0    0    0    0    0 3582  918    0    0]\n",
      " [   0    0    0    0    0    0 4458   42    0    0]\n",
      " [   0    0    0    0    0    0 4463   37    0    0]\n",
      " [   0    0    0    0    0    0 4500    0    0    0]\n",
      " [   0    0    0    0    0    0 3748  752    0    0]\n",
      " [   0    0    0    0    0    0 4438   62    0    0]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[   0    0    0    0    0    0  902  598    0    0]\n",
      " [   0    0    0    0    0    0 1288  211    1    0]\n",
      " [   0    0    0    0    0    0 1499    1    0    0]\n",
      " [   0    0    0    0    0    0 1406   94    0    0]\n",
      " [   0    0    0    0    0    0 1198  302    0    0]\n",
      " [   0    0    0    0    0    0 1487   13    0    0]\n",
      " [   0    0    0    0    0    0 1492    8    0    0]\n",
      " [   0    0    0    0    0    0 1500    0    0    0]\n",
      " [   0    0    0    0    0    0 1266  234    0    0]\n",
      " [   0    0    0    0    0    0 1478   21    1    0]]\n",
      "\n",
      "---\n",
      "\n",
      "test 05\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[2960  741   26  225    2    0  444    0   18   84]\n",
      " [ 136 3113    2    8    0    0  853   84    1  303]\n",
      " [  14  132 3537    8    0    0  272   84   60  393]\n",
      " [ 306  201   53 3404   76    0  301    2  146   11]\n",
      " [ 171  129   13 1607 1957   51   38    1  532    1]\n",
      " [   0    0    1  167   38 1595    4    0 2695    0]\n",
      " [ 110  386   94   45    0    0 3560  127    6  172]\n",
      " [   0  217  291   10    1    0 1180 2638   31  132]\n",
      " [ 155  125  127 1054   93   64  378   52 2400   52]\n",
      " [ 249  641  410    6    0    0  401   11    2 2780]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[ 953  246    6   94    0    0  159    0    8   34]\n",
      " [  48 1021    2    4    0    0  293   31    0  101]\n",
      " [   3   41 1184    2    0    0   94   16   20  140]\n",
      " [ 109   77   16 1113   21    0  112    0   44    8]\n",
      " [  54   44    4  557  624   11   10    1  194    1]\n",
      " [   0    0    1   55   14  559    2    0  869    0]\n",
      " [  35  131   25   13    0    0 1188   48    2   58]\n",
      " [   0   68  109    2    0    0  416  864   11   30]\n",
      " [  51   30   46  362   30   17  110   25  809   20]\n",
      " [  67  215  116    2    0    0  152    2    1  945]]\n",
      "\n",
      "---\n",
      "\n",
      "test 06\n",
      "\n",
      "Training data Confusion Matrix\n",
      "[[426  20   0   0   0   0   4   0   0   0]\n",
      " [  0 422   0   0   0   0  28   0   0   0]\n",
      " [  0   0 447   0   0   0   1   0   2   0]\n",
      " [  0   0   0 445   0   0   5   0   0   0]\n",
      " [  0   0   0 232 200   0   0   0  18   0]\n",
      " [  0   0   0   0   0 348   0   0 102   0]\n",
      " [  0   0   0   0   0   0 450   0   0   0]\n",
      " [  0   0   0   0   0   0   3 447   0   0]\n",
      " [  0   0   0  18   0   0   1   0 431   0]\n",
      " [  0  83   2   0   0   0   6   0   0 359]]\n",
      "\n",
      "\n",
      "Testing data Confusion Matrix\n",
      "[[139   8   0   0   0   0   1   0   0   2]\n",
      " [  0 145   0   0   0   0   5   0   0   0]\n",
      " [  0   0 150   0   0   0   0   0   0   0]\n",
      " [  0   0   0 150   0   0   0   0   0   0]\n",
      " [  0   0   0  86  59   0   0   0   5   0]\n",
      " [  0   0   0   0   0 117   0   0  33   0]\n",
      " [  0   0   0   0   0   0 150   0   0   0]\n",
      " [  0   0   0   0   0   0   3 147   0   0]\n",
      " [  0   0   0   6   0   0   0   0 144   0]\n",
      " [  0  25   1   0   0   0   1   0   0 123]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_04 = load_model('cnn_04.h5')\n",
    "\n",
    "print(\"cnn_04\\n\")\n",
    "\n",
    "print(\"test 01\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train_denoised) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test_denoised) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(45000, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(15000, 3, 1)\n",
    "\n",
    "prediction = cnn_04.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_04.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 02\\n\")\n",
    "prediction = cnn_04.predict(x_out_train_denoised)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_04.predict(x_out_test_denoised)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 03\\n\")\n",
    "after_autoencoder_x_train = autoencoder_02.predict(ae_x_out_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_02.predict(ae_x_out_test_noisy) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(45000, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(15000, 3, 1)\n",
    "\n",
    "prediction = cnn_04.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_04.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 04\\n\")\n",
    "after_autoencoder_x_train = autoencoder_03.predict(ae_x_in_train_noisy) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_03.predict(ae_x_in_test_noisy) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(45000, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(15000, 3, 1)\n",
    "\n",
    "prediction = cnn_04.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_04.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 05\\n\")\n",
    "after_autoencoder_x_train = autoencoder_01.predict(ae_x_in_train_noisy)\n",
    "after_autoencoder_x_test = autoencoder_01.predict(ae_x_in_test_noisy)\n",
    "after_autoencoder_x_train = autoencoder_04.predict(after_autoencoder_x_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(after_autoencoder_x_test) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(45000, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(15000, 3, 1)\n",
    "\n",
    "prediction = cnn_04.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_out_train_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_04.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_out_test_denoised, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "\n",
    "print(\"test 06\\n\")\n",
    "after_autoencoder_x_train = autoencoder_04.predict(ae_x_in_train) * (-100)\n",
    "after_autoencoder_x_test = autoencoder_04.predict(ae_x_in_test) * (-100)\n",
    "after_autoencoder_x_train = after_autoencoder_x_train.reshape(4500, 3, 1)\n",
    "after_autoencoder_x_test = after_autoencoder_x_test.reshape(1500, 3, 1)\n",
    "\n",
    "prediction = cnn_04.predict(after_autoencoder_x_train)\n",
    "cm = confusion_matrix(oh_y_in_train, prediction.argmax(axis=1)+1)\n",
    "print(\"Training data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "prediction = cnn_04.predict(after_autoencoder_x_test)\n",
    "cm = confusion_matrix(oh_y_in_test, prediction.argmax(axis=1)+1)\n",
    "print(\"Testing data Confusion Matrix\")\n",
    "print(cm)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
